<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">

<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png">
  <link rel="mask-icon" href="/assets/favicon/safari-pinned-tab.svg" color="#222">
  <link rel="manifest" href="/assets/favicon/site.webmanifest">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"symbioticlab.org","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.8.0","exturl":false,"sidebar":{"position":"right","display":"remove","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":true,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>
<meta name="description" content="Filters:                          (                 50&#x2F;50             )                                                                                  V">
<meta property="og:type" content="website">
<meta property="og:title" content="Publications">
<meta property="og:url" content="https://symbioticlab.org/publications/index.html">
<meta property="og:site_name" content="SymbioticLab">
<meta property="og:description" content="Filters:                          (                 50&#x2F;50             )                                                                                  V">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-07-23T03:10:02.000Z">
<meta property="article:modified_time" content="2020-07-23T03:10:02.000Z">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://symbioticlab.org/publications/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":false,"lang":"en","comments":true,"permalink":"https://symbioticlab.org/publications/index.html","path":"publications/index.html","title":"Publications"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Publications | SymbioticLab
</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">SymbioticLab</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">University of Michigan</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-projects"><a href="/projects" rel="section"><i class="fa fa-code fa-fw"></i>Projects</a></li>
        <li class="menu-item menu-item-publications"><a href="/publications" rel="section"><i class="fa fa-book fa-fw"></i>Publications</a></li>
        <li class="menu-item menu-item-people"><a href="/people" rel="section"><i class="fa fa-user fa-fw"></i>People</a></li>
        <li class="menu-item menu-item-funding"><a href="/funding" rel="section"><i class="fa fa-info fa-fw"></i>Funding</a></li>
        <li class="menu-item menu-item-github"><a href="https://github.com/SymbioticLab" rel="noopener" target="_blank"><i class="fab fa-github-alt fa-fw"></i>Github</a></li>
        <li class="menu-item menu-item-wiki"><a href="https://symbiotic.eecs.umich.edu/wiki" rel="noopener" target="_blank"><i class="fab fa-wikipedia-w fa-fw"></i>Wiki</a></li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner page posts-expand">
  
  


    
    
    
    <div class="post-block" lang="en"><header class="post-header">

<h1 class="post-title" itemprop="name headline">Publications
</h1>

<div class="post-meta-container">
</div>

</header>

      
      
      <div class="post-body">
          <!-- begin-publist-be204cf8 -->
<style type="text/css">
:root{--color-accent-emphasis:#0969da;--color-accent-fg:#0969da;--color-attention-emphasis:#bf8700;--color-attention-fg:#9a6700;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-border-subtle:rgba(27,31,36,0.15);--color-canvas-overlay:#fff;--color-canvas-subtle:#f6f8fa;--color-danger-emphasis:#cf222e;--color-danger-fg:#cf222e;--color-diffstat-addition-bg:#2da44e;--color-done-emphasis:#8250df;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-fg-on-emphasis:#fff;--color-neutral-emphasis:#6e7781;--color-neutral-emphasis-plus:#24292f;--color-neutral-muted:rgba(175,184,193,0.2);--color-neutral-subtle:rgba(234,238,242,0.5);--color-primer-canvas-backdrop:rgba(27,31,36,0.5);--color-select-menu-backdrop-border:transparent;--color-select-menu-tap-focus-bg:#b6e3ff;--color-select-menu-tap-highlight:rgba(175,184,193,0.5);--color-shadow-large:0 8px 24px rgba(140,149,159,0.2);--color-success-emphasis:#2da44e;--color-success-fg:#1a7f37}.tooltipped{position:relative}.tooltipped:after{-webkit-font-smoothing:subpixel-antialiased;word-wrap:break-word;background:var(--color-neutral-emphasis-plus);border-radius:6px;color:var(--color-fg-on-emphasis);content:attr(aria-label);font:normal normal 11px/1.5 -apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji;letter-spacing:normal;padding:.5em .75em;text-align:center;text-decoration:none;text-shadow:none;text-transform:none;white-space:pre;z-index:1000000}.tooltipped:after,.tooltipped:before{display:none;opacity:0;pointer-events:none;position:absolute}.tooltipped:before{border:6px solid transparent;color:var(--color-neutral-emphasis-plus);content:"";height:0;width:0;z-index:1000001}@keyframes tooltip-appear{0%{opacity:0}to{opacity:1}}.tooltipped:active:after,.tooltipped:active:before,.tooltipped:focus:after,.tooltipped:focus:before,.tooltipped:hover:after,.tooltipped:hover:before{animation-delay:.4s;animation-duration:.1s;animation-fill-mode:forwards;animation-name:tooltip-appear;animation-timing-function:ease-in;display:inline-block;text-decoration:none}.tooltipped-no-delay:active:after,.tooltipped-no-delay:active:before,.tooltipped-no-delay:focus:after,.tooltipped-no-delay:focus:before,.tooltipped-no-delay:hover:after,.tooltipped-no-delay:hover:before{animation-delay:0s}.tooltipped-multiline:active:after,.tooltipped-multiline:focus:after,.tooltipped-multiline:hover:after{display:table-cell}.tooltipped-s:after,.tooltipped-se:after,.tooltipped-sw:after{margin-top:6px;right:50%;top:100%}.tooltipped-s:before,.tooltipped-se:before,.tooltipped-sw:before{border-bottom-color:var(--color-neutral-emphasis-plus);bottom:-7px;margin-right:-6px;right:50%;top:auto}.tooltipped-se:after{left:50%;margin-left:-16px;right:auto}.tooltipped-sw:after{margin-right:-16px}.tooltipped-n:after,.tooltipped-ne:after,.tooltipped-nw:after{bottom:100%;margin-bottom:6px;right:50%}.tooltipped-n:before,.tooltipped-ne:before,.tooltipped-nw:before{border-top-color:var(--color-neutral-emphasis-plus);bottom:auto;margin-right:-6px;right:50%;top:-7px}.tooltipped-ne:after{left:50%;margin-left:-16px;right:auto}.tooltipped-nw:after{margin-right:-16px}.tooltipped-n:after,.tooltipped-s:after{transform:translateX(50%)}.tooltipped-w:after{bottom:50%;margin-right:6px;right:100%;transform:translateY(50%)}.tooltipped-w:before{border-left-color:var(--color-neutral-emphasis-plus);bottom:50%;left:-7px;margin-top:-6px;top:50%}.tooltipped-e:after{bottom:50%;left:100%;margin-left:6px;transform:translateY(50%)}.tooltipped-e:before{border-right-color:var(--color-neutral-emphasis-plus);bottom:50%;margin-top:-6px;right:-7px;top:50%}.tooltipped-align-right-1:after,.tooltipped-align-right-2:after{margin-right:0;right:0}.tooltipped-align-right-1:before{right:10px}.tooltipped-align-right-2:before{right:15px}.tooltipped-align-left-1:after,.tooltipped-align-left-2:after{left:0;margin-left:0}.tooltipped-align-left-1:before{left:5px}.tooltipped-align-left-2:before{left:10px}.tooltipped-multiline:after{word-wrap:break-word;border-collapse:separate;max-width:250px;white-space:pre-line;width:max-content}.tooltipped-multiline.tooltipped-n:after,.tooltipped-multiline.tooltipped-s:after{left:50%;right:auto;transform:translateX(-50%)}.tooltipped-multiline.tooltipped-e:after,.tooltipped-multiline.tooltipped-w:after{right:100%}@media screen and (min-width:0\0){.tooltipped-multiline:after{width:250px}}.tooltipped-sticky:after,.tooltipped-sticky:before{display:inline-block}.tooltipped-sticky.tooltipped-multiline:after{display:table-cell}.SelectMenu{bottom:0;display:flex;flex-direction:column;left:0;padding:16px;pointer-events:none;position:fixed;right:0;top:0;z-index:99}@media(min-width:544px){.SelectMenu{bottom:auto;left:auto;padding:0;position:absolute;right:auto;top:auto}}.SelectMenu:before{background-color:var(--color-primer-canvas-backdrop);bottom:0;content:"";left:0;pointer-events:none;position:absolute;right:0;top:0}@media(min-width:544px){.SelectMenu:before{display:none}}.SelectMenu-modal{animation:SelectMenu-modal-animation .12s cubic-bezier(0,.1,.1,1) backwards;background-color:var(--color-canvas-overlay);border:1px solid var(--color-select-menu-backdrop-border);border-radius:12px;box-shadow:var(--color-shadow-large);display:flex;flex-direction:column;margin:auto 0;max-height:66%;overflow:hidden;pointer-events:auto;position:relative;z-index:99}@keyframes SelectMenu-modal-animation{0%{opacity:0;transform:scale(.9)}}@keyframes SelectMenu-modal-animation--sm{0%{opacity:0;transform:translateY(-16px)}}@media(min-width:544px){.SelectMenu-modal{animation-name:SelectMenu-modal-animation--sm;border-color:var(--color-border-default);border-radius:6px;box-shadow:var(--color-shadow-large);font-size:12px;height:auto;margin:8px 0 16px;max-height:480px;width:300px}}.SelectMenu-header{align-items:center;border-bottom:1px solid var(--color-border-muted);display:flex;flex:none;padding:16px}@media(min-width:544px){.SelectMenu-header{padding:7px 7px 7px 16px}}.SelectMenu-title{flex:1;font-size:14px;font-weight:600}@media(min-width:544px){.SelectMenu-title{font-size:inherit}}.SelectMenu-closeButton{background-color:transparent;border:0;color:var(--color-fg-muted);line-height:1;margin:-16px;padding:16px}@media(min-width:544px){.SelectMenu-closeButton{margin:-8px -7px;padding:8px}}.SelectMenu-filter{border-bottom:1px solid var(--color-border-muted);margin:0;padding:16px}@media(min-width:544px){.SelectMenu-filter{padding:8px}}.SelectMenu-input{display:block;width:100%}@media(min-width:544px){.SelectMenu-input{font-size:14px}}.SelectMenu-list{-webkit-overflow-scrolling:touch;flex:auto;margin:0 0 -1px;overflow-x:hidden;overflow-y:auto;padding:0;position:relative}.SelectMenu-item,.SelectMenu-list{background-color:var(--color-canvas-overlay)}.SelectMenu-item{align-items:center;border:0;border-bottom:1px solid var(--color-border-muted);color:var(--color-fg-default);cursor:pointer;display:flex;overflow:hidden;padding:16px;text-align:left;width:100%}@media(min-width:544px){.SelectMenu-item{padding-bottom:7px;padding-top:7px}}.SelectMenu-list--borderless .SelectMenu-item{border-bottom:0}.SelectMenu-icon{flex-shrink:0;margin-right:8px;width:16px}.SelectMenu-icon--check{transform:scale(0);transition:transform .12s cubic-bezier(.5,.1,1,.5),visibility 0s linear .12s;visibility:hidden}.SelectMenu-tabs{-webkit-overflow-scrolling:touch;box-shadow:inset 0 -1px 0 var(--color-border-muted);display:flex;flex-shrink:0;overflow-x:auto;overflow-y:hidden}.SelectMenu-tabs::-webkit-scrollbar{display:none}@media(min-width:544px){.SelectMenu-tabs{padding:8px 8px 0}}.SelectMenu-tab{background-color:transparent;border:0;box-shadow:inset 0 -1px 0 var(--color-border-muted);color:var(--color-fg-muted);flex:1;font-size:12px;font-weight:500;padding:8px 16px;text-align:center}@media(min-width:544px){.SelectMenu-tab{border:solid transparent;border-top-left-radius:6px;border-top-right-radius:6px;border-width:1px 1px 0;flex:none;padding:4px 16px}}.SelectMenu-tab[aria-selected=true]{background-color:var(--color-canvas-overlay);box-shadow:0 0 0 1px var(--color-border-muted);color:var(--color-fg-default);cursor:default;z-index:1}@media(min-width:544px){.SelectMenu-tab[aria-selected=true]{border-color:var(--color-border-muted);box-shadow:none}}.SelectMenu-message{background-color:var(--color-canvas-overlay);border-bottom:1px solid var(--color-border-muted);padding:7px 16px;text-align:center}.SelectMenu-blankslate,.SelectMenu-loading{background-color:var(--color-canvas-overlay);padding:24px 16px;text-align:center}.SelectMenu-divider{background-color:var(--color-canvas-subtle);border-bottom:1px solid var(--color-border-muted);color:var(--color-fg-muted);font-size:12px;font-weight:500;margin:0;padding:4px 16px}.SelectMenu-list--borderless .SelectMenu-divider{border-top:1px solid var(--color-border-muted)}.SelectMenu-list--borderless .SelectMenu-divider:empty{border-top:0;padding:0}.SelectMenu-footer{border-top:1px solid var(--color-border-muted);color:var(--color-fg-muted);font-size:12px;padding:8px 16px;text-align:center;z-index:0}@media(min-width:544px){.SelectMenu-footer{padding:7px 16px}}.SelectMenu--hasFilter .SelectMenu-modal{height:80%;margin-top:0;max-height:none}@media(min-width:544px){.SelectMenu--hasFilter .SelectMenu-modal{height:auto;margin-top:8px;max-height:480px}}.SelectMenu-closeButton:focus,.SelectMenu-item:focus,.SelectMenu-tab:focus{outline:0}.SelectMenu-item:hover{text-decoration:none}.SelectMenu-item[aria-checked=true]{color:var(--color-fg-default);font-weight:500}.SelectMenu-item[aria-checked=true] .SelectMenu-icon--check{transform:scale(1);transition:transform .12s cubic-bezier(0,0,.2,1),visibility 0s linear;visibility:visible}.SelectMenu-item:disabled,.SelectMenu-item[aria-disabled=true]{color:var(--color-fg-muted);pointer-events:none}@media(hover:hover){.SelectMenu-closeButton:hover,body:not(.intent-mouse) .SelectMenu-closeButton:focus{color:var(--color-fg-default)}.SelectMenu-closeButton:active{color:var(--color-fg-muted)}.SelectMenu-item:hover,body:not(.intent-mouse) .SelectMenu-item:focus{background-color:var(--color-neutral-subtle)}.SelectMenu-item:active{background-color:var(--color-canvas-subtle)}body:not(.intent-mouse) .SelectMenu-tab:focus{background-color:var(--color-select-menu-tap-focus-bg)}.SelectMenu-tab:hover{color:var(--color-fg-default)}.SelectMenu-tab:not([aria-selected=true]):active{background-color:var(--color-canvas-subtle);color:var(--color-fg-default)}}@media(hover:none){.SelectMenu-item:active,.SelectMenu-item:focus{background-color:var(--color-canvas-subtle)}.SelectMenu-item{-webkit-tap-highlight-color:var(--color-select-menu-tap-highlight)}}.IssueLabel{border:1px solid transparent;border-radius:2em;display:inline-block;font-size:12px;font-weight:500;line-height:18px;padding:0 7px}.IssueLabel .g-emoji{display:inline-block;font-size:1em;line-height:1;position:relative;top:-.05em}.IssueLabel:hover{text-decoration:none}.IssueLabel--big{line-height:22px;padding-left:10px;padding-right:10px}.labels{position:relative}.label,.Label{background-color:transparent!important;border:1px solid transparent;border-color:var(--color-border-default);border-radius:2em;display:inline-block;font-size:12px;font-weight:500;line-height:18px;padding:0 7px}.label:hover,.Label:hover{text-decoration:none}.Label--large{line-height:22px;padding-left:10px;padding-right:10px}.Label--inline{display:inline;font-size:.9em;padding:.1667em .5em}.Label--primary{border-color:var(--color-neutral-emphasis);color:var(--color-fg-default)}.Label--secondary{border-color:var(--color-border-default);color:var(--color-fg-muted)}.Label--info{border-color:var(--color-accent-emphasis);color:var(--color-accent-fg)}.Label--success{border-color:var(--color-success-emphasis);color:var(--color-success-fg)}.Label--warning{border-color:var(--color-attention-emphasis);color:var(--color-attention-fg)}.Label--danger{border-color:var(--color-danger-emphasis);color:var(--color-danger-fg)}.state,.State{border-radius:2em;display:inline-block;font-size:14px;font-weight:500;line-height:20px;padding:5px 12px;text-align:center;white-space:nowrap}.state,.State,.State--draft{background-color:var(--color-neutral-emphasis);border:1px solid transparent;color:var(--color-fg-on-emphasis)}.State--open{background-color:var(--color-success-emphasis)}.State--merged,.State--open{color:var(--color-fg-on-emphasis)}.State--merged{background-color:var(--color-done-emphasis)}.State--closed{background-color:var(--color-danger-emphasis);color:var(--color-fg-on-emphasis)}.State--small{font-size:12px;line-height:24px;padding:0 10px}.State--small .octicon{width:1em}.Counter{background-color:var(--color-neutral-muted);border:1px solid transparent;border-radius:2em;color:var(--color-fg-default);display:inline-block;font-size:12px;font-weight:500;line-height:18px;min-width:20px;padding:0 6px;text-align:center}.Counter:empty{display:none}.Counter .octicon{opacity:.8;vertical-align:text-top}.Counter--primary{background-color:var(--color-neutral-emphasis);color:var(--color-fg-on-emphasis)}.Counter--secondary{background-color:var(--color-neutral-subtle);color:var(--color-fg-muted)}.diffstat{color:var(--color-fg-muted);cursor:default;font-size:12px;font-weight:600;white-space:nowrap}.diffstat-block-added,.diffstat-block-deleted,.diffstat-block-neutral{display:inline-block;height:8px;margin-left:1px;outline-offset:-1px;width:8px}.diffstat-block-deleted{background-color:var(--color-danger-emphasis);outline:1px solid var(--color-border-subtle)}.diffstat-block-added{background-color:var(--color-diffstat-addition-bg);outline:1px solid var(--color-border-subtle)}.diffstat-block-neutral{background-color:var(--color-neutral-muted);outline:1px solid var(--color-border-subtle)}.details-overlay[open]>summary:before{background:transparent;bottom:0;content:" ";cursor:default;display:block;left:0;position:fixed;right:0;top:0;z-index:80}.details-overlay-dark[open]>summary:before{background:var(--color-primer-canvas-backdrop);z-index:99}.details-reset>summary{list-style:none}.details-reset>summary:before{display:none}.details-reset>summary::-webkit-details-marker{display:none}.post-header .post-meta{display:none}.posts-expand{padding-top:0!important}.pub-list{line-height:1.5}.pub-list section.year{align-items:flex-start;display:flex;margin-left:3.5em;padding:1em 0 0;position:relative}.pub-list section.year ul li{position:relative}.pub-list section.year ul li:before{background:rgba(0,0,0,.3);bottom:0;content:" ";left:calc(-2em - 2px);position:absolute;top:-1px;width:2px;z-index:-1}.pub-list section.year ul li:not(.filter-hide):before{top:calc(-1em - 1px)}.pub-list section.year ul li:not(.filter-hide)~li:not(.filter-hide):before{top:-1px}.pub-list section.year:last-child ul li:last-child:before{background:linear-gradient(180deg,rgba(0,0,0,.3) 60%,transparent)}.pub-list .year-mark-wrapper{align-items:center;display:flex;position:sticky;top:5em;width:0}.pub-list .year-mark-wrapper:before{content:"A";visibility:hidden;width:0}.pub-list .year-mark{align-items:center;background:#c5c5c5;border:2px solid #fff;border-radius:10px;display:flex;flex-direction:row;height:10px;justify-content:flex-end;left:-8px;position:relative;width:10px;z-index:2}.pub-list .year-mark:before{content:attr(data-year);font-size:1rem;font-weight:700;margin-right:1em}@media(min-width:62em){.pub-list .year-mark:before{font-size:1.1rem}}.pub-list section.year ul{font-size:1em;margin:0;padding:0 0 0 2em;width:100%}@media(min-width:62em){.pub-list section.year section ul{font-size:1.1em;padding-left:2.2em}}.pub-list section.year ul li{border-bottom:1px dashed #ccc;list-style-type:none;padding:1rem 0 1.25rem}.pub-list section.year ul li:first-child{padding-top:0}.pub-list section.year:last-child ul li:last-child{border-bottom:none}.pub-block{text-align:left}.pub-block .pub-title{font-weight:700}.pub-block .pub-authors,.pub-block .pub-conference,.pub-block .pub-links{font-size:.9em}.pub-block .pub-conference{font-style:italic}.pub-block .pub-conference .pub-conference-acceptance{font-style:normal}.pub-block .pub-abstract-frame{height:0;overflow:hidden;transition:height .4s cubic-bezier(.02,.01,.47,1)}.pub-block .pub-abstract{padding:1em 0;text-align:justify}.pub-block .pub-abstract p:last-child{margin-bottom:0}.pub-block .pub-author.pub-highlight{font-weight:700}.filter-hide{display:none!important}.publist-search-panel .SelectMenu-modal{border-radius:0;width:auto}.publist-search-panel .SelectMenu{min-width:100%}.publist-search-panel details{position:relative}.publist-search-panel .SelectMenu-list--borderless .SelectMenu-divider:first-child{border-top:0}.publist-search-panel .SelectMenu-divider[aria-checked=true] .SelectMenu-icon--check{transform:scale(1);transition:transform .12s cubic-bezier(0,0,.2,1),visibility 0s linear;visibility:visible}.publist-search-panel .SelectMenu-divider{align-items:center;cursor:pointer;display:flex}.publist-search-panel{align-items:flex-start;background:#fff;border-bottom:1px dashed #ccc;display:flex;flex-direction:row;margin-top:-1em;padding:1em 0 .5em;position:sticky;top:0;z-index:11}.publist-search-panel .publist-filters-header{display:flex;flex-direction:column;margin-left:.5em;margin-right:1em}.publist-search-panel .publist-filters-header footer{align-self:center;font-size:small}.publist-filters-header .publist-filters-header-hwrapper{align-items:center;display:flex;height:calc(1.5rem + 4px);justify-content:stretch}.publist-filters-header h4{margin:0;padding:0}.publist-search-panel .publist-filters-row{align-items:center;display:flex;flex:1;flex-wrap:wrap;justify-content:left;margin-bottom:-.5rem;margin-top:-.5rem}.publist-search-panel details{margin:.5rem}.publist-search-panel details>summary[aria-haspopup=true]{align-items:center;cursor:pointer;display:flex;height:1.5rem;outline:none}.publist-search-panel [role=menuitem],.publist-search-panel details summary span{white-space:nowrap}.publist-search-panel .SelectMenu-item .display-value{margin-right:.5rem}.publist-search-panel .SelectMenu-item .Counter{margin-left:auto}.publist-search-panel .dropdown-caret{display:inline-block;height:1.25rem;margin-left:10px;position:relative;width:1.25rem}.publist-search-panel .dropdown-caret:before{left:0;transform:rotate(45deg)}.publist-search-panel .dropdown-caret:after,.publist-search-panel .dropdown-caret:before{background-color:var(--btn-default-border-color);content:"";display:inline-block;height:.1rem;position:absolute;top:.6rem;transition:all .2s ease;width:.75rem}.publist-search-panel .dropdown-caret:after{right:0;transform:rotate(-45deg)}.publist-search-panel details[open] .dropdown-caret:before{transform:rotate(-45deg)}.publist-search-panel details[open] .dropdown-caret:after{transform:rotate(45deg)}

</style>
<div class="publist">
    <div class="publist-search-panel">
        <div class="publist-filters-header">
            <div class="publist-filters-header-hwrapper">
                <h4>Filters:</h4>
            </div>
            <footer>(<a title="Reset Filters" href="#">
                <span class="selected-value">50</span>/50
            </a>)</footer>
        </div>
        <div class="publist-filters-row">
            <details class="details-reset details-overlay" data-select-for="venue">
            <summary class="btn" aria-haspopup="true">
                <span>
                    Venue:
                    <span class="summary-value">All</span>
                </span>
                <span class="dropdown-caret"></span>
            </summary>
            <div class="SelectMenu">
                <div class="SelectMenu-modal">
                    <div class="SelectMenu-list SelectMenu-list--borderless">
                        
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="!all"
                            aria-checked="true"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">All</span>
                            <span class="Counter">50</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="!others"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Others</span>
                            <span class="Counter">0</span>
                        </button><div class="SelectMenu-divider" role="menuitem" data-value="@Conferences">
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            Conferences
                        </div>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Conferences"
                            data-value="ATC"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">ATC</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Conferences"
                            data-value="EuroSys"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">EuroSys</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Conferences"
                            data-value="FAST"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">FAST</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Conferences"
                            data-value="MLSys"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">MLSys</span>
                            <span class="Counter">2</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Conferences"
                            data-value="MobiCom"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">MobiCom</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Conferences"
                            data-value="NSDI"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">NSDI</span>
                            <span class="Counter">7</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Conferences"
                            data-value="OSDI"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">OSDI</span>
                            <span class="Counter">4</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Conferences"
                            data-value="SIGCOMM"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">SIGCOMM</span>
                            <span class="Counter">4</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Conferences"
                            data-value="SIGMOD"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">SIGMOD</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Conferences"
                            data-value="SPAA"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">SPAA</span>
                            <span class="Counter">1</span>
                        </button><div class="SelectMenu-divider" role="menuitem" data-value="@Journals">
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            Journals
                        </div>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Journals"
                            data-value="IEEEAccess"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">IEEEAccess</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Journals"
                            data-value="JMIRMH"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">JMIRMH</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Journals"
                            data-value="Sensors"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Sensors</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Journals"
                            data-value="USENIX ;login:"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">USENIX ;login:</span>
                            <span class="Counter">1</span>
                        </button><div class="SelectMenu-divider" role="menuitem" data-value="@Technical Reports">
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            Technical Reports
                        </div>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Technical Reports"
                            data-value="Dissertation"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Dissertation</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Technical Reports"
                            data-value="arXiv"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">arXiv</span>
                            <span class="Counter">14</span>
                        </button><div class="SelectMenu-divider" role="menuitem" data-value="@Workshops">
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            Workshops
                        </div>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Workshops"
                            data-value="APNet"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">APNet</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Workshops"
                            data-value="GRADES-NDA"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">GRADES-NDA</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Workshops"
                            data-value="HotCloud"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">HotCloud</span>
                            <span class="Counter">2</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Workshops"
                            data-value="HotOS"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">HotOS</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Workshops"
                            data-value="KBNets"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">KBNets</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Workshops"
                            data-value="MAMA"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">MAMA</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@Workshops"
                            data-value="ResilientFL"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">ResilientFL</span>
                            <span class="Counter">1</span>
                        </button>
                    </div>
                </div>
            </div>
        </details><details class="details-reset details-overlay" data-select-for="topic">
            <summary class="btn" aria-haspopup="true">
                <span>
                    Topic:
                    <span class="summary-value">All</span>
                </span>
                <span class="dropdown-caret"></span>
            </summary>
            <div class="SelectMenu">
                <div class="SelectMenu-modal">
                    <div class="SelectMenu-list SelectMenu-list--borderless">
                        
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="!all"
                            aria-checked="true"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">All</span>
                            <span class="Counter">50</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="!others"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Others</span>
                            <span class="Counter">3</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="Big Data Systems"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Big Data Systems</span>
                            <span class="Counter">5</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="Carbon-Aware Systems"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Carbon-Aware Systems</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="Datacenter Networking"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Datacenter Networking</span>
                            <span class="Counter">10</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="Disaggregation"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Disaggregation</span>
                            <span class="Counter">12</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="Systems + AI"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Systems + AI</span>
                            <span class="Counter">12</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="Wide-Area Computing"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Wide-Area Computing</span>
                            <span class="Counter">16</span>
                        </button>
                    </div>
                </div>
            </div>
        </details><details class="details-reset details-overlay" data-select-for="tag">
            <summary class="btn" aria-haspopup="true">
                <span>
                    Tag:
                    <span class="summary-value">All</span>
                </span>
                <span class="dropdown-caret"></span>
            </summary>
            <div class="SelectMenu">
                <div class="SelectMenu-modal">
                    <div class="SelectMenu-list SelectMenu-list--borderless">
                        
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="!all"
                            aria-checked="true"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">All</span>
                            <span class="Counter">50</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="!others"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Others</span>
                            <span class="Counter">50</span>
                        </button>
                    </div>
                </div>
            </div>
        </details><details class="details-reset details-overlay" data-select-for="badge">
            <summary class="btn" aria-haspopup="true">
                <span>
                    Badge:
                    <span class="summary-value">All</span>
                </span>
                <span class="dropdown-caret"></span>
            </summary>
            <div class="SelectMenu">
                <div class="SelectMenu-modal">
                    <div class="SelectMenu-list SelectMenu-list--borderless">
                        
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="!all"
                            aria-checked="true"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">All</span>
                            <span class="Counter">50</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="!others"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Others</span>
                            <span class="Counter">42</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="Artifacts Available"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Artifacts Available</span>
                            <span class="Counter">4</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="Artifacts Functional"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Artifacts Functional</span>
                            <span class="Counter">4</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="Best Paper Award"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Best Paper Award</span>
                            <span class="Counter">3</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="Distinguished Artifact Award"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Distinguished Artifact Award</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="Featured Article"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Featured Article</span>
                            <span class="Counter">1</span>
                        </button>
                        <button class="SelectMenu-item" role="menuitem"
                            data-value-cat="@"
                            data-value="Results Reproduced"
                            aria-checked="false"
                        >
                            <svg class="SelectMenu-icon SelectMenu-icon--check" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.78 4.22C13.9204 4.36062 13.9993 4.55125 13.9993 4.75C13.9993 4.94875 13.9204 5.13937 13.78 5.28L6.53 12.53C6.38937 12.6704 6.19875 12.7493 6 12.7493C5.80125 12.7493 5.61062 12.6704 5.47 12.53L2.22 9.28C2.08752 9.13782 2.0154 8.94978 2.01882 8.75547C2.02225 8.56117 2.10096 8.37579 2.23838 8.23837C2.37579 8.10096 2.56118 8.02225 2.75548 8.01882C2.94978 8.01539 3.13782 8.08752 3.28 8.22L6 10.94L12.72 4.22C12.8606 4.07955 13.0512 4.00066 13.25 4.00066C13.4487 4.00066 13.6394 4.07955 13.78 4.22Z"></path></svg>
                            <span class="display-value">Results Reproduced</span>
                            <span class="Counter">4</span>
                        </button>
                    </div>
                </div>
            </div>
        </details>
        </div>
    </div> <!-- publist-search-panel -->
    <div class="pub-list">
        <section class="year">
            <div class="year-mark-wrapper">
                <span class="year-mark" data-year="2022"></span>
            </div>
            <ul>
                <li data-pub-venue="NSDI"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Datacenter Networking&quot;,&quot;Disaggregation&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/justitia:nsdi22/justitia-nsdi22.pdf">Justitia: Software multi-tenancy in hardware kernel-bypass networks</a>
                            <span class="Label Label--info">New</span>
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Yiwen-Zhang ">Yiwen&nbspZhang</span>, 
                            <span class="pub-author pub-author-Yue-Tan ">Yue&nbspTan</span>, 
                            <span class="pub-author pub-author-Brent-Stephens ">Brent&nbspStephens</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            The 19th USENIX Symposium on Networked Systems Design and Implementation
                            (<a target="_blank" title="19.4%"
                                href="https://www.usenix.org/conference/nsdi22">NSDI'22</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp19.4%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/justitia:nsdi22/justitia-nsdi22.pdf">[paper]</a>
                            <a target="_blank" href="https://github.com/SymbioticLab/Justitia">[code]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{justitia:nsdi22,
    author    = {Yiwen Zhang and Yue Tan and Brent Stephens and Mosharaf Chowdhury},
    booktitle = {USENIX NSDI},
    title     = {{Justitia}: Software Multi-Tenancy in Hardware Kernel-Bypass Networks},
    year      = {2022},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Kernel-bypass networking (KBN) is becoming the new norm in modern datacenters.
While hardware-based KBN offloads all dataplane tasks to specialized NICs to achieve better latency and CPU efficiency than software-based KBN, it also takes away the operators control over network sharing policies.</p>
<p>Providing policy support in multi-tenant hardware KBN brings unique challenges  namely,
preserving ultra-low latency and low CPU cost, finding a well-defined point of mediation, and rethinking traffic shapers.
We present Justitia to address these challenges with three key design aspects:
(i) Split Connection with message-level shaping,
(ii) sender-based resource mediation together with receiver-side updates, and
(iii) passive latency monitoring.
Using a latency target as its knob, Justitia enables multi-tenancy policies such as predictable latencies and fair/weighted resource sharing.
Our evaluation shows Justitia can effectively isolate latency-sensitive applications at the cost of slightly decreased utilization and ensure that throughput and bandwidth of the rest are not unfairly penalized.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="FAST"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Disaggregation&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/hydra:fast22/hydra-fast22.pdf">Hydra : Resilient and highly available remote memory</a>
                            <span class="Label Label--info">New</span>
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Youngmoon-Lee ">Youngmoon&nbspLee</span>, 
                            <span class="pub-author pub-author-Hasan-Al Maruf ">Hasan&nbspAl&nbspMaruf</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Asaf-Cidon ">Asaf&nbspCidon</span>, and 
                            <span class="pub-author pub-author-Kang-G. Shin ">Kang&nbspG.&nbspShin</span>
                        </div>
                        <div class="pub-conference">
                            The 20th USENIX Conference on File and Storage Technologies
                            (<a target="_blank" title="21.54%"
                                href="https://www.usenix.org/conference/fast22">FAST'22</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp21.54%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/hydra:fast22/hydra-fast22.pdf">[paper]</a>
                            <a target="_blank" href="https://github.com/SymbioticLab/hydra">[code]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{hydra:fast22,
    author    = {Youngmoon Lee and Hasan Al Maruf and Mosharaf Chowdhury and Asaf Cidon and Kang G. Shin},
    booktitle = {USENIX FAST},
    title     = {{Hydra} : Resilient and Highly Available Remote Memory},
    year      = {2022},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>We present Hydra, a low-latency, low-overhead, and highly available resilience mechanism for remote memory. Hydra can access erasure-coded remote memory within a single-digit <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi></mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal"></span></span></span></span>s read/write latency, significantly improving the performance-efficiency tradeoff over the state-of-the-art  it performs similar to in-memory replication with 1.6<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo></mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord"></span></span></span></span> lower memory overhead. We also propose CodingSets, a novel coding group placement algorithm for erasure-coded data, that provides load balancing while reducing the probability of data loss under correlated failures by an order of magnitude. With Hydra, even when only 50% memory is local, unmodified memory-intensive applications achieve performance close to that of the fully in-memory case in the presence of remote failures and outperforms the state-of-the-art remote-memory solutions by up to 4.35<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo></mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord"></span></span></span></span>.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="JMIRMH"
                    data-pub-cat="Journals"
                    data-pub-extra='{&quot;topic&quot;:[],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="https://doi.org/10.2196/34645">Risk factors for COVID-19 in college students identified by physical, mental, and social health reported during the Fall 2020 semester: Observational study using the Roadmap app and Fitbit wearable sensors</a>
                            <span class="Label Label--info">New</span>
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Kristen-N Gilley ">Kristen&nbspN&nbspGilley</span>, 
                            <span class="pub-author pub-author-Loubna-Baroudi ">Loubna&nbspBaroudi</span>, 
                            <span class="pub-author pub-author-Miao-Yu ">Miao&nbspYu</span>, 
                            <span class="pub-author pub-author-Izzy-Gainsburg ">Izzy&nbspGainsburg</span>, 
                            <span class="pub-author pub-author-Niyanth-Reddy ">Niyanth&nbspReddy</span>, 
                            <span class="pub-author pub-author-Christina-Bradley ">Christina&nbspBradley</span>, 
                            <span class="pub-author pub-author-Christine-Cislo ">Christine&nbspCislo</span>, 
                            <span class="pub-author pub-author-Michelle-Lois Rozwadowski ">Michelle&nbspLois&nbspRozwadowski</span>, 
                            <span class="pub-author pub-author-Caroline-Ashley Clingan ">Caroline&nbspAshley&nbspClingan</span>, 
                            <span class="pub-author pub-author-Matthew-Stephen DeMoss ">Matthew&nbspStephen&nbspDeMoss</span>, 
                            <span class="pub-author pub-author-Tracey-Churay ">Tracey&nbspChuray</span>, 
                            <span class="pub-author pub-author-Kira-Birditt ">Kira&nbspBirditt</span>, 
                            <span class="pub-author pub-author-Natalie-Colabianchi ">Natalie&nbspColabianchi</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Daniel-Forger ">Daniel&nbspForger</span>, 
                            <span class="pub-author pub-author-Joel-Gagnier ">Joel&nbspGagnier</span>, 
                            <span class="pub-author pub-author-Ronald-F Zernicke ">Ronald&nbspF&nbspZernicke</span>, 
                            <span class="pub-author pub-author-Julia-Lee Cunningham ">Julia&nbspLee&nbspCunningham</span>, 
                            <span class="pub-author pub-author-Stephen-M Cain ">Stephen&nbspM&nbspCain</span>, 
                            <span class="pub-author pub-author-Muneesh-Tewari ">Muneesh&nbspTewari</span>, and 
                            <span class="pub-author pub-author-Sung-Won Choi ">Sung&nbspWon&nbspChoi</span>
                        </div>
                        <div class="pub-conference">
                            JMIR Mental Health 2022, 9(2):e34645
                            (<a target="_blank" title=""
                                href="https://doi.org/10.2196/34645">JMIR-MH:9(2)</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="https://doi.org/10.2196/34645">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{covid-f20:jmirmh,
    author="Gilley, Kristen N and Baroudi, Loubna and Yu, Miao and Gainsburg, Izzy and Reddy, Niyanth and Bradley, Christina and Cislo, Christine and Rozwadowski, Michelle Lois and Clingan, Caroline Ashley and DeMoss, Matthew Stephen and Churay, Tracey and Birditt, Kira and Colabianchi, Natalie and Chowdhury, Mosharaf and Forger, Daniel and Gagnier, Joel and Zernicke, Ronald F and Cunningham, Julia Lee and Cain, Stephen M and Tewari, Muneesh and Choi, Sung Won",
    title="Risk Factors for {COVID-19} in College Students Identified by Physical, Mental, and Social Health Reported During the {Fall 2020} Semester: Observational Study Using the {Roadmap} App and {Fitbit} Wearable Sensors",
    journal="JMIR Mental Health",
    year="2022",
    month="Feb",
    day="10",
    volume="9",
    number="2",
    pages="e34645",
    publisher={JMIR Publications},
    abstract="Background: The COVID-19 pandemic triggered a seismic shift in education to web-based learning. With nearly 20 million students enrolled in colleges across the United States, the long-simmering mental health crisis in college students was likely further exacerbated by the pandemic. Objective: This study leveraged mobile health (mHealth) technology and sought to (1) characterize self-reported outcomes of physical, mental, and social health by COVID-19 status; (2) assess physical activity through consumer-grade wearable sensors (Fitbit); and (3) identify risk factors associated with COVID-19 positivity in a population of college students prior to release of the vaccine. Methods: After completing a baseline assessment (ie, at Time 0 [T0]) of demographics, mental, and social health constructs through the Roadmap 2.0 app, participants were instructed to use the app freely, wear the Fitbit, and complete subsequent assessments at T1, T2, and T3, followed by a COVID-19 assessment of history and timing of COVID-19 testing and diagnosis (T4: {\textasciitilde}14 days after T3). Continuous measures were described using mean (SD) values, while categorical measures were summarized as n ({\%}) values. Formal comparisons were made on the basis of COVID-19 status. The multivariate model was determined by entering all statistically significant variables (P<.05) in univariable associations at once and then removing one variable at a time through backward selection until the optimal model was obtained. Results: During the fall 2020 semester, 1997 participants consented, enrolled, and met criteria for data analyses. There was a high prevalence of anxiety, as assessed by the State Trait Anxiety Index, with moderate and severe levels in 465 (24{\%}) and 970 (49{\%}) students, respectively. Approximately one-third of students reported having a mental health disorder (n=656, 33{\%}). The average daily steps recorded in this student population was approximately 6500 (mean 6474, SD 3371). Neither reported mental health nor step count were significant based on COVID-19 status (P=.52). Our analyses revealed significant associations of COVID-19 positivity with the use of marijuana and alcohol (P=.02 and P=.046, respectively) and with lower belief in public health measures (P=.003). In addition, graduate students were less likely and those with 20 roommates were more likely to report a COVID-19 diagnosis (P=.009). Conclusions: Mental health problems were common in this student population. Several factors, including substance use, were associated with the risk of COVID-19. These data highlight important areas for further attention, such as prioritizing innovative strategies that address health and well-being, considering the potential long-term effects of COVID-19 on college students. Trial Registration: ClinicalTrials.gov NCT04766788; https://clinicaltrials.gov/ct2/show/NCT04766788 International Registered Report Identifier (IRRID): RR2-10.2196/29561 ",
    issn="2368-7959",
    doi="10.2196/34645"
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Background: The COVID-19 pandemic triggered a seismic shift in education to web-based learning. With nearly 20 million students enrolled in colleges across the United States, the long-simmering mental health crisis in college students was likely further exacerbated by the pandemic. Objective: This study leveraged mobile health (mHealth) technology and sought to (1) characterize self-reported outcomes of physical, mental, and social health by COVID-19 status; (2) assess physical activity through consumer-grade wearable sensors (Fitbit); and (3) identify risk factors associated with COVID-19 positivity in a population of college students prior to release of the vaccine. Methods: After completing a baseline assessment (ie, at Time 0 [T0]) of demographics, mental, and social health constructs through the Roadmap 2.0 app, participants were instructed to use the app freely, wear the Fitbit, and complete subsequent assessments at T1, T2, and T3, followed by a COVID-19 assessment of history and timing of COVID-19 testing and diagnosis (T4: ~14 days after T3). Continuous measures were described using mean (SD) values, while categorical measures were summarized as n (%) values. Formal comparisons were made on the basis of COVID-19 status. The multivariate model was determined by entering all statistically significant variables (P.05) in univariable associations at once and then removing one variable at a time through backward selection until the optimal model was obtained. Results: During the fall 2020 semester, 1997 participants consented, enrolled, and met criteria for data analyses. There was a high prevalence of anxiety, as assessed by the State Trait Anxiety Index, with moderate and severe levels in 465 (24%) and 970 (49%) students, respectively. Approximately one-third of students reported having a mental health disorder (n=656, 33%). The average daily steps recorded in this student population was approximately 6500 (mean 6474, SD 3371). Neither reported mental health nor step count were significant based on COVID-19 status (P=.52). Our analyses revealed significant associations of COVID-19 positivity with the use of marijuana and alcohol (P=.02 and P=.046, respectively) and with lower belief in public health measures (P=.003). In addition, graduate students were less likely and those with 20 roommates were more likely to report a COVID-19 diagnosis (P=.009). Conclusions: Mental health problems were common in this student population. Several factors, including substance use, were associated with the risk of COVID-19. These data highlight important areas for further attention, such as prioritizing innovative strategies that address health and well-being, considering the potential long-term effects of COVID-19 on college students. Trial Registration: ClinicalTrials.gov NCT04766788; https://clinicaltrials.gov/ct2/show/NCT04766788 International Registered Report Identifier (IRRID): RR2-10.2196/29561
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="arXiv"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Systems + AI&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="https://arxiv.org/abs/2201.06227">Efficient DNN training with knowledge-guided layer freezing</a>
                            <span class="Label Label--info">New</span>
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Yiding-Wang ">Yiding&nbspWang</span>, 
                            <span class="pub-author pub-author-Decang-Sun ">Decang&nbspSun</span>, 
                            <span class="pub-author pub-author-Kai-Chen ">Kai&nbspChen</span>, 
                            <span class="pub-author pub-author-Fan-Lai ">Fan&nbspLai</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            arXiv
                            (<a target="_blank" title=""
                                href="https://arxiv.org/abs/2201.06227">arXiv:2201.06227</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="https://arxiv.org/abs/2201.06227">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{egeria:arxiv22,
    author        = {Yiding Wang and Decang Sun and Kai Chen and Fan Lai and Mosharaf Chowdhury},
    journal       = {CoRR},
    title         = {Efficient DNN Training with Knowledge-Guided Layer Freezing},
    year          = {2022},
    month         = {Jan},
    volume        = {abs/2201.06227},
    archiveprefix = {arXiv},
    eprint        = {2201.06227},
    url           = {https://arxiv.org/abs/2201.06227},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Training deep neural networks (DNNs) is time-consuming. While most existing solutions try to overlap/schedule computation and communication for efficient training, this paper goes one step further by skipping computing and communication through DNN layer freezing. Our key insight is that the training progress of internal DNN layers differs significantly, and front layers often become well-trained much earlier than deep layers. To explore this, we first introduce the notion of training plasticity to quantify the training progress of internal DNN layers. Then we design KGT, a knowledge-guided DNN training system that employs semantic knowledge from a reference model to accurately evaluate individual layers training plasticity and safely freeze the converged ones, saving their corresponding backward computation and communication. Our reference model is generated on the fly using quantization techniques and runs forward operations asynchronously on available CPUs to minimize the overhead. In addition, KGT caches the intermediate outputs of the frozen layers with prefetching to further skip the forward computation. Our implementation and testbed experiments with popular vision and language models show that KGT achieves 19%-43% training speedup w.r.t. the state-of-the-art without sacrificing accuracy.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="arXiv"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Carbon-Aware Systems&quot;,&quot;Disaggregation&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="https://arxiv.org/abs/2201.02120">Treehouse: A case for carbon-aware datacenter software</a>
                            <span class="Label Label--info">New</span>
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Thomas-Anderson ">Thomas&nbspAnderson</span>, 
                            <span class="pub-author pub-author-Adam-Belay ">Adam&nbspBelay</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Asaf-Cidon ">Asaf&nbspCidon</span>, and 
                            <span class="pub-author pub-author-Irene-Zhang ">Irene&nbspZhang</span>
                        </div>
                        <div class="pub-conference">
                            arXiv
                            (<a target="_blank" title=""
                                href="https://arxiv.org/abs/2201.02120">arXiv:2201.02120</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="https://arxiv.org/abs/2201.02120">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{treehouse-whitepaper:arxiv22,
    author        = {Thomas Anderson and Adam Belay and Mosharaf Chowdhury and Asaf Cidon and Irene Zhang},
    journal       = {CoRR},
    title         = {Treehouse: A Case For Carbon-Aware Datacenter Software},
    year          = {2022},
    month         = {Jan},
    volume        = {abs/2201.02120},
    archiveprefix = {arXiv},
    eprint        = {2201.02120},
    url           = {https://arxiv.org/abs/2201.02120},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>The end of Dennard scaling and the slowing of Moores Law has put the energy use of datacenters on an unsustainable path. Datacenters are already a significant fraction of worldwide electricity use, with application demand scaling at a rapid rate. We argue that substantial reductions in the carbon intensity of datacenter computing are possible with a software-centric approach: by making energy and carbon visible to application developers on a fine-grained basis, by modifying system APIs to make it possible to make informed trade offs between performance and carbon emissions, and by raising the level of application programming to allow for flexible use of more energy efficient means of compute and storage. We also lay out a research agenda for systems software to reduce the carbon footprint of datacenter computing.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
            </ul>
        </section>
        <section class="year">
            <div class="year-mark-wrapper">
                <span class="year-mark" data-year="2021"></span>
            </div>
            <ul>
                <li data-pub-venue="IEEEAccess"
                    data-pub-cat="Journals"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[&quot;Featured Article&quot;]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="https://doi.org/10.1109/ACCESS.2021.3127448">The Internet of Federated Things (IoFT)</a>
                            
                        </div>
                        <div class="pub-badges">
                            <span class="Label Label--danger pub-badge">Featured Article</span>
                        </div>
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Raed-Kontar ">Raed&nbspKontar</span>, 
                            <span class="pub-author pub-author-Naichen-Shi ">Naichen&nbspShi</span>, 
                            <span class="pub-author pub-author-Xubo-Yue ">Xubo&nbspYue</span>, 
                            <span class="pub-author pub-author-Seokhyun-Chung ">Seokhyun&nbspChung</span>, 
                            <span class="pub-author pub-author-Eunshin-Byon ">Eunshin&nbspByon</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Judy-Jin ">Judy&nbspJin</span>, 
                            <span class="pub-author pub-author-Wissam-Kontar ">Wissam&nbspKontar</span>, 
                            <span class="pub-author pub-author-Neda-Masoud ">Neda&nbspMasoud</span>, 
                            <span class="pub-author pub-author-Maher-Noueihed ">Maher&nbspNoueihed</span>, 
                            <span class="pub-author pub-author-Chinedum-E Okwudire ">Chinedum&nbspE&nbspOkwudire</span>, 
                            <span class="pub-author pub-author-Garvesh-Raskutti ">Garvesh&nbspRaskutti</span>, 
                            <span class="pub-author pub-author-Romesh-Saigal ">Romesh&nbspSaigal</span>, 
                            <span class="pub-author pub-author-Karandeep-Singh ">Karandeep&nbspSingh</span>, and 
                            <span class="pub-author pub-author-Zhisheng-Ye ">Zhisheng&nbspYe</span>
                        </div>
                        <div class="pub-conference">
                            IEEE Access 2021, 9, 156071-156113
                            (<a target="_blank" title=""
                                href="https://doi.org/10.1109/ACCESS.2021.3127448">IEEEAccess:9</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="https://doi.org/10.1109/ACCESS.2021.3127448">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{ioft-survey:ieee-access,
    title={The {I}nternet of {F}ederated {T}hings ({IoFT})},
    author={Raed Kontar and Naichen Shi and Xubo Yue and Seokhyun Chung and Eunshin Byon and Mosharaf Chowdhury and Judy Jin and Wissam Kontar and Neda Masoud and Maher Noueihed and Chinedum E Okwudire and Garvesh Raskutti and Romesh Saigal and Karandeep Singh and Zhisheng Ye},
    journal={IEEE Access},
    volume={9},
    pages={156071--156113},
    year={2021},
    publisher={IEEE},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>The Internet of Things (IoT) is on the verge of a major paradigm shift. In the IoT system of the future, IoFT, the cloud will be substituted by the crowd where model training is brought to the edge, allowing IoT devices to collaboratively extract knowledge and build smart analytics/models while keeping their personal data stored locally. This paradigm shift was set into motion by the tremendous increase in computational power on IoT devices and the recent advances in decentralized and privacy-preserving model training, coined as federated learning (FL). This article provides a vision for IoFT and a systematic overview of current efforts towards realizing this vision. Specifically, we first introduce the defining characteristics of IoFT and discuss FL data-driven approaches, opportunities, and challenges that allow decentralized inference within three dimensions: (i) a global model that maximizes utility across all IoT devices, (ii) a personalized model that borrows strengths across all devices yet retains its own model, (iii) a meta-learning model that quickly adapts to new devices or learning tasks. We end by describing the vision and challenges of IoFT in reshaping different industries through the lens of domain experts. Those industries include manufacturing, transportation, energy, healthcare, quality &amp; reliability, business, and computing.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="arXiv"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/ioft-survey:arxiv21/ioft-survey-arxiv21.pdf"><span class="nocase">The Internet of Federated Things (IoFT)</span>: A vision for the future and in-depth survey of data-driven approaches for federated learning</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Raed-Kontar ">Raed&nbspKontar</span>, 
                            <span class="pub-author pub-author-Naichen-Shi ">Naichen&nbspShi</span>, 
                            <span class="pub-author pub-author-Xubo-Yue ">Xubo&nbspYue</span>, 
                            <span class="pub-author pub-author-Seokhyun-Chung ">Seokhyun&nbspChung</span>, 
                            <span class="pub-author pub-author-Eunshin-Byon ">Eunshin&nbspByon</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Judy-Jin ">Judy&nbspJin</span>, 
                            <span class="pub-author pub-author-Wissam-Kontar ">Wissam&nbspKontar</span>, 
                            <span class="pub-author pub-author-Neda-Masoud ">Neda&nbspMasoud</span>, 
                            <span class="pub-author pub-author-Maher-Noueihed ">Maher&nbspNoueihed</span>, 
                            <span class="pub-author pub-author-Chinedum-E Okwudire ">Chinedum&nbspE&nbspOkwudire</span>, 
                            <span class="pub-author pub-author-Garvesh-Raskutti ">Garvesh&nbspRaskutti</span>, 
                            <span class="pub-author pub-author-Romesh-Saigal ">Romesh&nbspSaigal</span>, 
                            <span class="pub-author pub-author-Karandeep-Singh ">Karandeep&nbspSingh</span>, and 
                            <span class="pub-author pub-author-Zhisheng-Ye ">Zhisheng&nbspYe</span>
                        </div>
                        <div class="pub-conference">
                            arXiv
                            (<a target="_blank" title=""
                                href="https://arxiv.org/abs/2111.05326">arXiv:2111.05326</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/ioft-survey:arxiv21/ioft-survey-arxiv21.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{ioft-survey:arxiv21,
    title={{The Internet of Federated Things (IoFT)}: A Vision for the Future and In-Depth Survey of Data-Driven Approaches for Federated Learning},
    author={Raed Kontar and Naichen Shi and Xubo Yue and Seokhyun Chung and Eunshin Byon and Mosharaf Chowdhury and Judy Jin and Wissam Kontar and Neda Masoud and Maher Noueihed and Chinedum E Okwudire and Garvesh Raskutti and Romesh Saigal and Karandeep Singh and Zhisheng Ye},
    archiveprefix = {arXiv},
    eprint= {2111.05326},
    url= {https://arxiv.org/abs/2111.05326},
    year={2021},
    month={November},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>The Internet of Things (IoT) is on the verge of a major paradigm shift. In the IoT system of the future, IoFT, the cloud will be substituted by the crowd where model training is brought to the edge, allowing IoT devices to collaboratively extract knowledge and build smart analytics/models while keeping their personal data stored locally. This paradigm shift was set into motion by the tremendous increase in computational power on IoT devices and the recent advances in decentralized and privacy-preserving model training, coined as federated learning (FL). This article provides a vision for IoFT and a systematic overview of current efforts towards realizing this vision. Specifically, we first introduce the defining characteristics of IoFT and discuss FL data-driven approaches, opportunities, and challenges that allow decentralized inference within three dimensions: (i) a global model that maximizes utility across all IoT devices, (ii) a personalized model that borrows strengths across all devices yet retains its own model, (iii) a meta-learning model that quickly adapts to new devices or learning tasks. We end by describing the vision and challenges of IoFT in reshaping different industries through the lens of domain experts. Those industries include manufacturing, transportation, energy, healthcare, quality &amp; reliability, business, and computing.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="ResilientFL"
                    data-pub-cat="Workshops"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;,&quot;Systems + AI&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[&quot;Best Paper Award&quot;]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/fedscale:resilientfl21/fedscale-resilientfl21.pdf">FedScale: Benchmarking model and system performance of federated learning</a>
                            
                        </div>
                        <div class="pub-badges">
                            <span class="Label Label--danger pub-badge">Best Paper Award</span>
                        </div>
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Fan-Lai ">Fan&nbspLai</span>, 
                            <span class="pub-author pub-author-Yinwei-Dai ">Yinwei&nbspDai</span>, 
                            <span class="pub-author pub-author-Xiangfeng-Zhu ">Xiangfeng&nbspZhu</span>, 
                            <span class="pub-author pub-author-Harsha-V. Madhyastha ">Harsha&nbspV.&nbspMadhyastha</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            ACM SOSP 21 Workshop on Systems Challenges in Reliable and Secure Federated Learning
                            (<a target="_blank" title=""
                                href="https://resilientfl.org/">ResilientFL'21</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/fedscale:resilientfl21/fedscale-resilientfl21.pdf">[paper]</a>
                            <a target="_blank" href="https://github.com/SymbioticLab/fedscale">[code]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{fedscale:resilientfl21,
    author    = {Fan Lai and Yinwei Dai and Xiangfeng Zhu and Harsha V. Madhyastha and Mosharaf Chowdhury},
    booktitle = {ACM SOSP ResilientFL},
    title     = {FedScale: Benchmarking Model and System Performance of Federated Learning},
    year      = {2021},
}
">[bibtex]</a>
                            
                        </div>
                        
                    </div>
                </li>
                <li data-pub-venue="SIGCOMM"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Datacenter Networking&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[&quot;Artifacts Available&quot;,&quot;Artifacts Functional&quot;,&quot;Results Reproduced&quot;]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/aifo:sigcomm21/aifo-sigcomm21.pdf">Programmable packet scheduling with a single queue</a>
                            
                        </div>
                        <div class="pub-badges">
                            <span class="Label Label--danger pub-badge">Artifacts Available</span>
                            <span class="Label Label--danger pub-badge">Artifacts Functional</span>
                            <span class="Label Label--danger pub-badge">Results Reproduced</span>
                        </div>
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Zhuolong-Yu ">Zhuolong&nbspYu</span>, 
                            <span class="pub-author pub-author-Chuheng-Hu ">Chuheng&nbspHu</span>, 
                            <span class="pub-author pub-author-Jingfeng-Wu ">Jingfeng&nbspWu</span>, 
                            <span class="pub-author pub-author-Xiao-Sun ">Xiao&nbspSun</span>, 
                            <span class="pub-author pub-author-Vladimir-Braverman ">Vladimir&nbspBraverman</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Zhenhua-Liu ">Zhenhua&nbspLiu</span>, and 
                            <span class="pub-author pub-author-Xin-Jin ">Xin&nbspJin</span>
                        </div>
                        <div class="pub-conference">
                            The 2021 ACM SIGCOMM Conference
                            (<a target="_blank" title="22.82%"
                                href="https://conferences.sigcomm.org/sigcomm/2021/">SIGCOMM'21</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp22.82%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/aifo:sigcomm21/aifo-sigcomm21.pdf">[paper]</a>
                            <a target="_blank" href="https://github.com/netx-repo/AIFO">[code]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{aifo:sigcomm21,
    author    = {Zhuolong Yu and Chuheng Hu and Jingfeng Wu and Xiao Sun and Vladimir Braverman and Mosharaf Chowdhury and Zhenhua Liu and Xin Jin},
    booktitle = {ACM SIGCOMM},
    title     = {Programmable Packet Scheduling with a Single Queue},
    year      = {2021},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Programmable packet scheduling enables scheduling algorithms to be programmed into the data plane without changing the hardware. Existing proposals either have no hardware implementations for switch ASICs or require multiple strict-priority queues.</p>
<p>We present Admission-In First-Out (AIFO) queues, a new solution for programmable packet scheduling that uses only a single first-in first-out queue. AIFO is motivated by the confluence of two recent trends: shallow buffers in switches and fast-converging congestion control in end hosts, that together leads to a simple observation: the decisive factor in a flows completion time (FCT) in modern datacenter networks is often which packets are enqueued or dropped, not the ordering they leave the switch. The core idea of AIFO is to maintain a sliding window to track the ranks of recent packets and compute the relative rank of an arriving packet in the window for admission control. Theoretically, we prove that AIFO provides bounded performance to Push-In First-Out (PIFO). Empirically, we fully implement AIFO and evaluate AIFO with a range of real workloads, demonstrating AIFO closely approximates PIFO. Importantly, unlike PIFO, AIFO can run at line rate on existing hardware and use minimal switch resourcesas few as a single queue.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="arXiv"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Disaggregation&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="https://arxiv.org/abs/2108.06893">Memtrade: A disaggregated-memory marketplace for public clouds</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Hasan-Al Maruf ">Hasan&nbspAl&nbspMaruf</span>, 
                            <span class="pub-author pub-author-Yuhong-Zhong ">Yuhong&nbspZhong</span>, 
                            <span class="pub-author pub-author-Hongyi-Wang ">Hongyi&nbspWang</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Asaf-Cidon ">Asaf&nbspCidon</span>, and 
                            <span class="pub-author pub-author-Carl-Waldspurger ">Carl&nbspWaldspurger</span>
                        </div>
                        <div class="pub-conference">
                            arXiv
                            (<a target="_blank" title=""
                                href="https://arxiv.org/abs/2108.06893">arXiv:2108.06893</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="https://arxiv.org/abs/2108.06893">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{memtrade:arxiv21,
    author        = {Hasan Al Maruf and Yuhong Zhong and Hongyi Wang and Mosharaf Chowdhury and Asaf Cidon and Carl Waldspurger},
    journal       = {CoRR},
    title         = {Memtrade: A Disaggregated-Memory Marketplace for Public Clouds},
    year          = {2021},
    month         = {Aug},
    volume        = {abs/2108.06893},
    archiveprefix = {arXiv},
    eprint        = {2108.06893},
    url           = {https://arxiv.org/abs/2108.06893},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>We present Memtrade, the first memory disaggregation system for public clouds. Public clouds introduce a set of unique challenges for resource disaggregation across different tenants, including security, isolation and pricing. Memtrade allows producer virtual machines (VMs) to lease both their unallocated memory and allocated-but-idle application memory to remote consumer VMs for a limited period of time. Memtrade does not require any modifications to host-level system software or support from the cloud provider. It harvests producer memory using an application-aware control loop to form a distributed transient remote memory pool with minimal performance impact; it employs a broker to match producers with consumers while satisfying performance constraints; and it exposes the matched memory to consumers as a secure KV cache. Our evaluation using real-world cluster traces shows that Memtrade provides significant performance benefit for consumers (improving average read latency up to 2.8x) while preserving confidentiality and integrity, with little impact on producer applications (degrading performance by less than 2.1%).</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="Dissertation"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/jcgu:dissertation/jcgu-dissertation.pdf">Efficient resource management for deep learning clusters</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Juncheng-Gu ">Juncheng&nbspGu</span>
                        </div>
                        <div class="pub-conference">
                            PhD Dissertation
                            (<a target="_blank" title=""
                                href="">dissertation</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/jcgu:dissertation/jcgu-dissertation.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@phdthesis{jcgu:dissertation,
    Title                    = {Efficient Resource Management for Deep Learning Clusters},
    Author                   = {Juncheng Gu},
    Institution              = {University of Michigan},
    Year                     = {2021},
    Month                    = {August},
    Abstract                 = {Deep Learning (DL) is gaining rapid popularity in various domains, such as computer vision, speech recognition, etc. With the increasing demands, large clusters have been built to develop DL models (i.e., data preparation and model training). DL jobs have some unique features ranging from their hardware requirements to execution patterns. However, the resource management techniques applied in existing DL clusters have not yet been adapted to those new features, which leads to resource inefficiency and hurts the perfor- mance of DL jobs.
  We observed three major challenges brought by DL jobs. First, data preparation jobs, which prepare training datasets from a large volume of raw data, are memory intensive. DL clusters often over-allocate memory resource to those jobs for protecting their performance, which causes memory underutilization in DL clusters. Second, the execution time of a DL training job is often unknown before job completion. Without such information, existing cluster schedulers are unable to minimize the average Job Completion Time (JCT) of those jobs. Third, model aggregations in Distributed Deep Learning (DDL) training are often assigned with a fixed group of CPUs. However, a large portion of those CPUs are wasted because the bursty model aggregations can not saturate them all the time.
  In this thesis, we propose a suite of techniques to eliminate the mismatches between DL jobs and resource management in DL clusters. First, we bring the idea of memory disaggregation to enhance the memory utilization of DL clusters. The unused memory in data preparation jobs is exposed as remote memory to other machines that are running out of local memory. Second, we design a two-dimensional attained-service-based scheduler to optimize the average JCT of DL training jobs. This scheduler takes the temporal and spatial characteristics of DL training jobs into consideration and can efficiently schedule them without knowing their execution time. Third, we define a shared model aggregation service to reduce the CPU cost of DDL training. Using this service, model aggregations from different DDL training jobs are carefully packed together and use the same group of CPUs in a time-sharing manner. With these techniques, we demonstrate that huge improvements in resource efficiency and job performance can be obtained when the clusters resource management matches with the features of DL jobs.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Deep Learning (DL) is gaining rapid popularity in various domains, such as computer vision, speech recognition, etc. With the increasing demands, large clusters have been built to develop DL models (i.e., data preparation and model training). DL jobs have some unique features ranging from their hardware requirements to execution patterns. However, the resource management techniques applied in existing DL clusters have not yet been adapted to those new features, which leads to resource inefficiency and hurts the perfor- mance of DL jobs. We observed three major challenges brought by DL jobs. First, data preparation jobs, which prepare training datasets from a large volume of raw data, are memory intensive. DL clusters often over-allocate memory resource to those jobs for protecting their performance, which causes memory underutilization in DL clusters. Second, the execution time of a DL training job is often unknown before job completion. Without such information, existing cluster schedulers are unable to minimize the average Job Completion Time (JCT) of those jobs. Third, model aggregations in Distributed Deep Learning (DDL) training are often assigned with a fixed group of CPUs. However, a large portion of those CPUs are wasted because the bursty model aggregations can not saturate them all the time. In this thesis, we propose a suite of techniques to eliminate the mismatches between DL jobs and resource management in DL clusters. First, we bring the idea of memory disaggregation to enhance the memory utilization of DL clusters. The unused memory in data preparation jobs is exposed as remote memory to other machines that are running out of local memory. Second, we design a two-dimensional attained-service-based scheduler to optimize the average JCT of DL training jobs. This scheduler takes the temporal and spatial characteristics of DL training jobs into consideration and can efficiently schedule them without knowing their execution time. Third, we define a shared model aggregation service to reduce the CPU cost of DDL training. Using this service, model aggregations from different DDL training jobs are carefully packed together and use the same group of CPUs in a time-sharing manner. With these techniques, we demonstrate that huge improvements in resource efficiency and job performance can be obtained when the clusters resource management matches with the features of DL jobs.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="OSDI"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;,&quot;Systems + AI&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[&quot;Artifacts Available&quot;,&quot;Artifacts Functional&quot;,&quot;Results Reproduced&quot;,&quot;Distinguished Artifact Award&quot;]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/oort:osdi21/oort-osdi21.pdf">Oort: Efficient federated learning via guided participant selection</a>
                            
                        </div>
                        <div class="pub-badges">
                            <span class="Label Label--danger pub-badge">Artifacts Available</span>
                            <span class="Label Label--danger pub-badge">Artifacts Functional</span>
                            <span class="Label Label--danger pub-badge">Results Reproduced</span>
                            <span class="Label Label--danger pub-badge">Distinguished Artifact Award</span>
                        </div>
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Fan-Lai ">Fan&nbspLai</span>, 
                            <span class="pub-author pub-author-Xiangfeng-Zhu ">Xiangfeng&nbspZhu</span>, 
                            <span class="pub-author pub-author-Harsha-V. Madhyastha ">Harsha&nbspV.&nbspMadhyastha</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            The 15th USENIX Symposium on Operating Systems Design and Implementation
                            (<a target="_blank" title="18.79%"
                                href="https://www.usenix.org/conference/osdi21">OSDI'21</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp18.79%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/oort:osdi21/oort-osdi21.pdf">[paper]</a>
                            <a target="_blank" href="https://github.com/SymbioticLab/Oort">[code]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{oort:osdi21,
    author    = {Fan Lai and Xiangfeng Zhu and Harsha V. Madhyastha and Mosharaf Chowdhury},
    booktitle = {USENIX OSDI},
    title     = {Oort: Efficient Federated Learning via Guided Participant Selection},
    year      = {2021},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Federated Learning (FL) is an emerging direction in distributed machine learning (ML) that enables in-situ model training and testing on edge data. Despite having the same end goals as traditional ML, FL executions differ significantly in scale, spanning thousands to millions of participating devices. As a result, data characteristics and device capabilities vary widely across clients. Yet, existing efforts randomly select FL participants, which leads to poor model and system efficiency.
In this paper, we propose Kuiper to improve the performance of federated training and testing with guided participant selection. With an aim to improve time-to-accuracy performance in model training, Kuiper prioritizes the use of those clients who have both data that offers the greatest utility in improving model accuracy and the capability to run training quickly. To enable FL developers to interpret their results in model testing, Kuiper enforces their requirements on the distribution of participant data while improving the duration of federated testing by cherry-picking clients. Our evaluation shows that, compared to existing participant selection mechanisms, Kuiper improves time-to-accuracy performance by 1.2-14.1 and final model accuracy by 1.3%-9.8%, while efficiently enforcing developer-specified model testing criteria at the scale of millions of clients.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="arXiv"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/fed-ensemble:arxiv21/fed-ensemble-arxiv21.pdf">Fed-ensemble: Improving generalization through model ensembling in federated learning</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Naichen-Shi ">Naichen&nbspShi</span>, 
                            <span class="pub-author pub-author-Fan-Lai ">Fan&nbspLai</span>, 
                            <span class="pub-author pub-author-Raed-Al Kontar ">Raed&nbspAl&nbspKontar</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            arXiv
                            (<a target="_blank" title=""
                                href="https://arxiv.org/abs/2107.10663">arXiv:2107.10663</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/fed-ensemble:arxiv21/fed-ensemble-arxiv21.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{fed-ensemble:arxiv21,
    title={Fed-ensemble: Improving Generalization through Model Ensembling in Federated Learning},
    author={Naichen Shi and Fan Lai and Raed Al Kontar and Mosharaf Chowdhury},
    archiveprefix = {arXiv},
    eprint= {2107.10663},
    url= {https://arxiv.org/abs/2107.10663},
    year={2021},
    month={July},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>In this paper we propose Fed-ensemble: a simple approach that brings model ensembling to
federated learning (FL). Instead of aggregating local models to update a single global model, Fed-ensemble
uses random permutations to update a group of K models and then obtains predictions
through model averaging. Fed-ensemble can be readily utilized within established FL methods and
does not impose a computational overhead as it only requires one of the K models to be sent to a
client in each communication round. Theoretically, we show that predictions on new data from all K
models belong to the same predictive posterior distribution under a neural tangent kernel regime.
This result in turn sheds light on the generalization advantages of model averaging. We also illustrate
that Fed-ensemble has an elegant Bayesian interpretation. Empirical results show that our model
has superior performance over several FL algorithms, on a wide range of data sets, and excels in
heterogeneous settings often encountered in FL applications.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="arXiv"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;,&quot;Systems + AI&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/fedscale:arxiv21/fedscale-arxiv21.pdf">FedScale: Benchmarking model and system performance of federated learning</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Fan-Lai ">Fan&nbspLai</span>, 
                            <span class="pub-author pub-author-Yinwei-Dai ">Yinwei&nbspDai</span>, 
                            <span class="pub-author pub-author-Xiangfeng-Zhu ">Xiangfeng&nbspZhu</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            arXiv
                            (<a target="_blank" title=""
                                href="https://arxiv.org/abs/2105.11367">arXiv:2105.11367</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/fedscale:arxiv21/fedscale-arxiv21.pdf">[paper]</a>
                            <a target="_blank" href="https://github.com/SymbioticLab/FedScale">[code]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{fedscale:arxiv21,
    title={FedScale: Benchmarking Model and System Performance of Federated Learning},
    author={Lai, Fan and Dai, Yinwei and Zhu, Xiangfeng and Chowdhury, Mosharaf},
    archiveprefix = {arXiv},
    eprint= {2105.11367},
    url= {https://arxiv.org/abs/2105.11367},
    year={2021},
    month={May},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>We present FedScale, a diverse set of challenging and realistic benchmark datasets to facilitate scalable, comprehensive, and reproducible
federated learning (FL) research. FedScale datasets are large-scale, encompassing a diverse range of important FL tasks, such as image
classification, object detection, language modeling, speech recognition, and reinforcement learning. For each dataset, we provide a unified
evaluation protocol using realistic data splits and evaluation metrics. To meet the pressing need for reproducing realistic FL at scale,</p>
<p>we have also built an efficient evaluation platform to simplify and standardize the process of FL experimental setup and model evaluation.
Our evaluation platform provides flexible APIs to implement new FL algorithms and include new execution backends with minimal developer
efforts. Finally, we perform indepth benchmark experiments on these datasets. Our experiments suggest that FedScale presents significant
challenges of heterogeneity-aware co-optimizations of the system and statistical efficiency under realistic FL characteristics,
indicating fruitful opportunities for future research. FedScale is open-source with permissive licenses and actively maintained, and
we welcome feedback and contributions from the community.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="NSDI"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Disaggregation&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/kayak:nsdi21/kayak-nsdi21.pdf">Ship compute or ship data? Why not both?</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Jie-You ">Jie&nbspYou</span>, 
                            <span class="pub-author pub-author-Jingfeng-Wu ">Jingfeng&nbspWu</span>, 
                            <span class="pub-author pub-author-Xin-Jin ">Xin&nbspJin</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            The 18th USENIX Symposium on Networked Systems Design and Implementation
                            (<a target="_blank" title="15.99%"
                                href="https://www.usenix.org/conference/nsdi21">NSDI'21</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp15.99%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/kayak:nsdi21/kayak-nsdi21.pdf">[paper]</a>
                            <a target="_blank" href="https://github.com/SymbioticLab/Kayak">[code]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{kayak:nsdi21,
    author    = {Jie You and Jingfeng Wu and Xin Jin and Mosharaf Chowdhury},
    booktitle = {USENIX NSDI},
    title     = {Ship Compute or Ship Data? Why Not Both?},
    year      = {2021},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>How cloud applications should interact with their data re-mains an active area of research. Over the last decade, manyhave suggested relying on a key-value (KV) interface to inter-act with data stored in remote storage servers, while othershave vouched for the benefits of using remote procedure call(RPC). Instead of choosing one over the other, in this paper,we observe that an ideal solution must adaptively combineboth of them in order to maximize throughput while meetingapplication latency requirements. To this end, we proposea new system called Kayak that proactively adjusts the rateof requests and the fraction of requests to be executed usingRPC or KV, all in a fully decentralized and self-regulated man-ner. We theoretically prove that Kayak can quickly convergeto the optimal parameters.  We implement a system proto-type of Kayak. Our evaluations show that Kayak achievessub-second convergence  and improves  overall throughputby 32.5%-63.4% for compute-intensive workloads and upto 12.2% for non-compute-intensive and transactional work-loads over the state-of-the-art.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="MLSys"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Systems + AI&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/fluid:mlsys21/fluid-mlsys21.pdf">Fluid: Resource-aware hyperparameter tuning engine</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Peifeng-Yu ">Peifeng&nbspYu</span>, 
                            <span class="pub-author pub-author-Jiachen-Liu ">Jiachen&nbspLiu</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            The 4th Conference on Machine Learning and Systems
                            (<a target="_blank" title="23.5%"
                                href="https://mlsys.org/Conferences/2021">MLSys'21</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp23.5%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/fluid:mlsys21/fluid-mlsys21.pdf">[paper]</a>
                            <a target="_blank" href="/publications/files/fluid:mlsys21/fluid-mlsys21.pptx">[slides]</a>
                            <a target="_blank" href="/publications/files/fluid:mlsys21/fluid-mlsys21-poster.pdf">[poster]</a>
                            <a target="_blank" href="https://github.com/SymbioticLab/fluid">[code]</a>
                            <a target="_blank" href="https://www.youtube.com/watch?v=LZQE90whvfY">[video (oral)]</a>
                            <a target="_blank" href="https://www.youtube.com/watch?v=yaBxEUxRXZI">[video (poster)]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{fluid:mlsys21,
    author    = {Peifeng Yu and Jiachen Liu and Mosharaf Chowdhury},
    booktitle = {MLSys},
    title     = {Fluid: Resource-Aware Hyperparameter Tuning Engine},
    year      = {2021},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Current hyperparameter tuning solutions lack complementary execution engines to efficiently leverage distributed
computation, thus ignoring the possibility of intra- and inter-GPU sharing, which exhibits poor resource usage.
In this paper, we present Fluid, a generalized hyperparameter tuning execution engine, that coordinates between
hyperparameter tuning jobs and cluster resources. Fluid schedules evaluation trials in such jobs using a waterfilling
approach to make the best use of resources both at intra- and inter-GPU granularities to speed up the tuning
process. By abstracting a hyperparameter tuning job as a sequence of TrialGroup, Fluid can boost the performance
of diverse hyperparameter tuning solutions. Our experiments show that Fluid can speed up synchronous BOHB by
100%, and BOHB and ASHA by 30% while having similar final accuracy.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
            </ul>
        </section>
        <section class="year">
            <div class="year-mark-wrapper">
                <span class="year-mark" data-year="2020"></span>
            </div>
            <ul>
                <li data-pub-venue="Sensors"
                    data-pub-cat="Journals"
                    data-pub-extra='{&quot;topic&quot;:[],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="https://www.mdpi.com/1424-8220/20/21/6100">A systematic review of machine learning techniques in hematopoietic stem cell transplantation (HSCT)</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Vibhuti-Gupta ">Vibhuti&nbspGupta</span>, 
                            <span class="pub-author pub-author-Thomas-M Braun ">Thomas&nbspM&nbspBraun</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Muneesh-Tewari ">Muneesh&nbspTewari</span>, and 
                            <span class="pub-author pub-author-Sung-Won Choi ">Sung&nbspWon&nbspChoi</span>
                        </div>
                        <div class="pub-conference">
                            Sensors 2020, 20(21), 6100
                            (<a target="_blank" title=""
                                href="https://www.mdpi.com/1424-8220/20/21">Sensors:20(21)</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="https://www.mdpi.com/1424-8220/20/21/6100">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{hsct-survey,
    title={A Systematic Review of Machine Learning Techniques in Hematopoietic Stem Cell Transplantation ({HSCT})},
    author={Gupta, Vibhuti and Braun, Thomas M and Chowdhury, Mosharaf and Tewari, Muneesh and Choi, Sung Won},
    journal={Sensors},
    volume={20},
    number={21},
    pages={6100},
    year={2020},
    publisher={Multidisciplinary Digital Publishing Institute},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Machine learning techniques are widely used nowadays in the healthcare domain for the diagnosis, prognosis, and treatment of diseases. These techniques have applications in the field of hematopoietic cell transplantation (HCT), which is a potentially curative therapy for hematological malignancies. Herein, a systematic review of the application of machine learning (ML) techniques in the HCT setting was conducted. We examined the type of data streams included, specific ML techniques used, and type of clinical outcomes measured. A systematic review of English articles using PubMed, Scopus, Web of Science, and IEEE Xplore databases was performed. Search terms included hematopoietic cell transplantation (HCT), autologous HCT, allogeneic HCT, machine learning, and artificial intelligence. Only full-text studies reported between January 2015 and July 2020 were included. Data were extracted by two authors using predefined data fields. Following PRISMA guidelines, a total of 242 studies were identified, of which 27 studies met the inclusion criteria. These studies were sub-categorized into three broad topics and the type of ML techniques used included ensemble learning (63%), regression (44%), Bayesian learning (30%), and support vector machine (30%). The majority of studies examined models to predict HCT outcomes (e.g., survival, relapse, graft-versus-host disease). Clinical and genetic data were the most commonly used predictors in the modeling process. Overall, this review provided a systematic review of ML techniques applied in the context of HCT. The evidence is not sufficiently robust to determine the optimal ML technique to use in the HCT setting and/or what minimal data variables are required.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="arXiv"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;,&quot;Systems + AI&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/oort:arxiv20/oort-arxiv20.pdf">Oort: Informed participant selection for scalable federated learning</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Fan-Lai ">Fan&nbspLai</span>, 
                            <span class="pub-author pub-author-Xiangfeng-Zhu ">Xiangfeng&nbspZhu</span>, 
                            <span class="pub-author pub-author-Harsha-V. Madhyastha ">Harsha&nbspV.&nbspMadhyastha</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            arXiv
                            (<a target="_blank" title=""
                                href="https://arxiv.org/abs/2010.06081">arXiv:2010.06081</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/oort:arxiv20/oort-arxiv20.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{oort:arxiv20,
    author        = {Fan Lai and Xiangfeng Zhu and Harsha V. Madhyastha and Mosharaf Chowdhury},
    journal       = {CoRR},
    title         = {Oort: Informed Participant Selection for Scalable Federated Learning},
    year          = {2020},
    month         = {Oct},
    volume        = {abs/2010.06081},
    archiveprefix = {arXiv},
    bibsource     = {dblp computer science bibliography, https://dblp.org},
    biburl        = {https://dblp.org/rec/journals/corr/abs-2010-06081.bib},
    eprint        = {2010.06081},
    url           = {https://arxiv.org/abs/2010.06081},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Federated Learning (FL) is an emerging direction in distributed machine learning (ML) that enables in-situ model training and testing on edge data. Despite having the same end goals as traditional ML, FL executions differ significantly in scale, spanning thousands to millions of participating devices. As a result, data characteristics and device capabilities vary widely across clients. Yet, existing efforts randomly select FL participants, which leads to poor model and system efficiency.</p>
<p>In this paper, we propose Kuiper to improve the performance of federated training and testing with guided participant selection. With an aim to improve time-to-accuracy performance in model training, Kuiper prioritizes the use of those clients who have both data that offers the greatest utility in improving model accuracy and the capability to run training quickly. To enable FL developers to interpret their results in model testing, Kuiper enforces their requirements on the distribution of participant data while improving the duration of federated testing by cherry-picking clients. Our evaluation shows that, compared to existing participant selection mechanisms, Kuiper improves time-to-accuracy performance by 1.2x-14.1x and final model accuracy by 1.3%-9.8%, while efficiently enforcing developer-specified model testing criteria at the scale of millions of clients.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="SIGCOMM"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Datacenter Networking&quot;,&quot;Disaggregation&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[&quot;Artifacts Available&quot;,&quot;Artifacts Functional&quot;,&quot;Results Reproduced&quot;]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/netlock:sigcomm20/netlock-sigcomm20.pdf">NetLock: Fast, centralized lock management using programmable switches</a>
                            
                        </div>
                        <div class="pub-badges">
                            <span class="Label Label--danger pub-badge">Artifacts Available</span>
                            <span class="Label Label--danger pub-badge">Artifacts Functional</span>
                            <span class="Label Label--danger pub-badge">Results Reproduced</span>
                        </div>
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Zhuolong-Yu ">Zhuolong&nbspYu</span>, 
                            <span class="pub-author pub-author-Yiwen-Zhang ">Yiwen&nbspZhang</span>, 
                            <span class="pub-author pub-author-Vladimir-Braverman ">Vladimir&nbspBraverman</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Xin-Jin ">Xin&nbspJin</span>
                        </div>
                        <div class="pub-conference">
                            The 2020 ACM SIGCOMM Conference
                            (<a target="_blank" title="21.6%"
                                href="https://conferences.sigcomm.org/sigcomm/2020/">SIGCOMM'20</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp21.6%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/netlock:sigcomm20/netlock-sigcomm20.pdf">[paper]</a>
                            <a target="_blank" href="https://github.com/netx-repo/NetLock">[code]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{netlock:sigcomm20,
    author    = {Zhuolong Yu and Yiwen Zhang and Vladimir Braverman and Mosharaf Chowdhury and Xin Jin},
    booktitle = {ACM SIGCOMM},
    title     = {{NetLock}: Fast, Centralized Lock Management Using Programmable Switches},
    year      = {2020},
    pages     = {126--138},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Lock managers are widely used by distributed systems. Traditional centralized lock managers can easily support policies between multiple users using global knowledge, but they suffer from low performance. In contrast, emerging decentralized approaches are faster but cannot provide flexible policy support. Furthermore, performance in both cases is limited by the server capability.</p>
<p>We present NetLock, a new centralized lock manager that co-designs servers and network switches to achieve high performance without sacrificing flexibility in policy support. The key idea of NetLock is to exploit the capability of emerging programmable switches to directly process lock requests in the switch data plane. Due to the limited switch memory, we design a memory management mechanism to seamlessly integrate the switch and server memory. To realize the locking functionality in the switch, we design a custom data plane module that efficiently pools multiple register arrays together to maximize memory utilization We have implemented a NetLock prototype with a Barefoot Tofino switch and a cluster of commodity servers. Evaluation results show that NetLock improves the throughput by 14.0-18.4x, and reduces the average and 99% latency by 4.7-20.3x and 10.4-18.7x over DSLR, a state-of-the-art RDMA-based solution, while providing flexible policy support.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="ATC"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Disaggregation&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[&quot;Best Paper Award&quot;]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/leap:atc20/leap-atc20.pdf">Effectively prefetching remote memory with Leap</a>
                            
                        </div>
                        <div class="pub-badges">
                            <span class="Label Label--danger pub-badge">Best Paper Award</span>
                        </div>
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Hasan-Al Maruf ">Hasan&nbspAl&nbspMaruf</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            The 2020 USENIX Annual Technical Conference
                            (<a target="_blank" title="18.68%"
                                href="https://www.usenix.org/conference/atc20">ATC'20</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp18.68%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/leap:atc20/leap-atc20.pdf">[paper]</a>
                            <a target="_blank" href="/publications/files/leap:atc20/leap-atc20-slides.pdf">[slides]</a>
                            <a target="_blank" href="https://github.com/SymbioticLab/Leap">[code]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{leap:atc20,
    author    = {Hasan Al Maruf and Mosharaf Chowdhury},
    booktitle = {USENIX ATC},
    title     = {Effectively Prefetching Remote Memory with {Leap}},
    year      = {2020},
    pages     = {843--857},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Memory disaggregation over RDMA can improve the performance of memory-constrained applications by replacing disk swapping with remote memory accesses. However, state-of-the-art memory disaggregation solutions still use data path components designed for slow disks. As a result, applications experience remote memory access latency significantly higher than that of the underlying low-latency network, which itself can be too high for many applications.</p>
<p>In this paper, we propose Leap, a prefetching solution for remote memory accesses due to memory disaggregation. At its core, Leap employs an online, majority-based prefetching algorithm, which increases the page cache hit rate. We complement it with a lightweight and efficient data path in the kernel that isolates each applications data path to the disaggregated memory and mitigates latency bottlenecks arising from legacy throughput-optimizing operations. Integration of Leap in the Linux kernel improves the median and tail remote page access latencies of memory-bound applications by up to 104.04 and 22.62, respectively, over the default data path. This leads to up to 10.16 performance improvements for applications using disaggregated memory in comparison to the state-of-the-art solutions.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="EuroSys"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Systems + AI&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/allox:eurosys20/allox-eurosys20.pdf">AlloX: Compute allocation in hybrid clusters</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Tan-N. Le ">Tan&nbspN.&nbspLe</span>, 
                            <span class="pub-author pub-author-Xiao-Sun ">Xiao&nbspSun</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Zhenhua-Liu ">Zhenhua&nbspLiu</span>
                        </div>
                        <div class="pub-conference">
                            The Fifteenth European Conference on Computer Systems
                            (<a target="_blank" title="18.38%"
                                href="https://www.eurosys2020.org/">EuroSys'20</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp18.38%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/allox:eurosys20/allox-eurosys20.pdf">[paper]</a>
                            <a target="_blank" href="https://github.com/lenhattan86/allox">[code]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{allox:eurosys20,
    author    = {Tan N. Le and Xiao Sun and Mosharaf Chowdhury and Zhenhua Liu},
    booktitle = {ACM EuroSys},
    title     = {{AlloX}: Compute Allocation in Hybrid Clusters},
    year      = {2020},
    pages     = {31:1--31:16},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Modern deep learning frameworks support a variety of hardware, including CPU, GPU, and other accelerators, to perform computation. In this paper, we study how to schedule jobs over such interchangeable resources  each with a different rate of computation  to optimize performance while providing fairness among users in a shared cluster. We demonstrate theoretically and empirically that existing solutions and their straightforward modifications perform poorly in the presence of interchangeable resources, which motivates the design and implementation of AlloX. At its core, AlloX transforms the scheduling problem into a min-cost bipartite matching problem and provides dynamic fair allocation over time. We theoretically prove its optimality in an ideal, offline setting and show empirically that it works well in the online scenario by incorporating with Kubernetes. Evaluations on a small-scale CPU-GPU hybrid cluster and large-scale simulations highlight that AlloX can reduce the average job completion time significantly (by up to 95% when the system load is high) while providing fairness and preventing starvation.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="MLSys"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Systems + AI&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[&quot;Artifacts Available&quot;,&quot;Artifacts Functional&quot;,&quot;Results Reproduced&quot;]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/salus:mlsys20/salus-mlsys20.pdf">Salus: Fine-grained GPU sharing primitives for deep learning applications</a>
                            
                        </div>
                        <div class="pub-badges">
                            <span class="Label Label--danger pub-badge">Artifacts Available</span>
                            <span class="Label Label--danger pub-badge">Artifacts Functional</span>
                            <span class="Label Label--danger pub-badge">Results Reproduced</span>
                        </div>
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Peifeng-Yu ">Peifeng&nbspYu</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            The 3rd Conference on Machine Learning and Systems
                            (<a target="_blank" title="19.2%"
                                href="https://mlsys.org/Conferences/2020">MLSys'20</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp19.2%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/salus:mlsys20/salus-mlsys20.pdf">[paper]</a>
                            <a target="_blank" href="/publications/files/salus:mlsys20/salus-mlsys20-talk.pptm">[slides]</a>
                            <a target="_blank" href="/publications/files/salus:mlsys20/salus-mlsys20-poster.pdf">[poster]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{salus:mlsys20,
    author    = {Peifeng Yu and Mosharaf Chowdhury},
    booktitle = {MLSys},
    title     = {Salus: Fine-Grained {GPU} Sharing Primitives for Deep Learning Applications},
    year      = {2020},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Unlike traditional resources such as CPU or the network, modern GPUs do not natively support
fine-grained sharing primitives.
Consequently, implementing common policies such as time sharing and preemption are expensive. Worse,
when a deep learning (DL) application cannot completely use a GPUs resources, the GPU cannot be efficiently shared
between multiple applications, leading to GPU underutilization.</p>
<p>We present Salus to enable two GPU sharing primitives: <strong>fast job
switching</strong> and <strong>memory sharing</strong>, to achieve fine-grained GPU sharing
among multiple DL applications. Salus is an efficient, consolidated
execution service that exposes the GPU to different DL applications, and it
enforces fine-grained sharing by performing iteration scheduling and
addressing associated memory management issues. We show that these primitives
can then be used to implement flexible sharing policies. Our integration of
Salus with TensorFlow and evaluation on popular DL jobs shows that Salus
can improve the average completion time of DL training jobs by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3.19</mn><mo></mo></mrow><annotation encoding="application/x-tex">3.19\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mord">.</span><span class="mord">1</span><span class="mord">9</span><span class="mord"></span></span></span></span>, GPU utilization for
hyper-parameter tuning by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2.38</mn><mo></mo></mrow><annotation encoding="application/x-tex">2.38\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mord">.</span><span class="mord">3</span><span class="mord">8</span><span class="mord"></span></span></span></span>, and GPU utilization of DL inference applications by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>42</mn><mo></mo></mrow><annotation encoding="application/x-tex">42\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mord">2</span><span class="mord"></span></span></span></span> over not sharing
the GPU and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn><mo></mo></mrow><annotation encoding="application/x-tex">6\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">6</span><span class="mord"></span></span></span></span> over NVIDIA MPS with small overhead.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="NSDI"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/sol:nsdi20/sol-nsdi20.pdf">Sol: Fast distributed computation over slow networks</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Fan-Lai ">Fan&nbspLai</span>, 
                            <span class="pub-author pub-author-Jie-You ">Jie&nbspYou</span>, 
                            <span class="pub-author pub-author-Xiangfeng-Zhu ">Xiangfeng&nbspZhu</span>, 
                            <span class="pub-author pub-author-Harsha-V. Madhyastha ">Harsha&nbspV.&nbspMadhyastha</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            The 17th USENIX Symposium on Networked Systems Design and Implementation
                            (<a target="_blank" title="18.36%"
                                href="https://www.usenix.org/conference/nsdi20">NSDI'20</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp18.36%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/sol:nsdi20/sol-nsdi20.pdf">[paper]</a>
                            <a target="_blank" href="/publications/files/sol:nsdi20/sol-nsdi20-slides.pdf">[slides]</a>
                            <a target="_blank" href="https://github.com/SymbioticLab/Sol">[code]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{sol:nsdi20,
    author    = {Fan Lai and Jie You and Xiangfeng Zhu and Harsha V. Madhyastha and Mosharaf Chowdhury},
    booktitle = {USENIX NSDI},
    title     = {Sol: Fast Distributed Computation Over Slow Networks},
    year      = {2020},
    pages     = {273--288},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>The popularity of big data and AI has led to many optimizations at different layers of distributed computation stacks. Despite  or perhaps, because of  its role as the narrow waist of such software stacks, the design of the execution engine, which is in charge of executing every single task of a job, has mostly remained unchanged. As a result, the execution engines available today are ones primarily designed for low latency and high bandwidth datacenter networks. When either or both of the network assumptions do not hold, CPUs are significantly underutilized.</p>
<p>In this paper, we take a first-principles approach toward developing an execution engine that can adapt to diverse network conditions. Sol, our federated execution engine architecture, flips the status quo in two respects. First, to mitigate the impact of high latency, Sol proactively assigns tasks, but does so judiciously to be resilient to uncertainties. Second, to improve the overall resource utilization, Sol decouples communication from computation internally instead of committing resources to both aspects of a task simultaneously. Our evaluations on EC2 show that, compared to Apache Spark in resource-constrained networks, Sol improves SQL and machine learning jobs by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16.4</mn><mo></mo></mrow><annotation encoding="application/x-tex">16.4\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">6</span><span class="mord">.</span><span class="mord">4</span><span class="mord"></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4.2</mn><mo></mo></mrow><annotation encoding="application/x-tex">4.2\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mord">.</span><span class="mord">2</span><span class="mord"></span></span></span></span> on average.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="NSDI"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/pando:nsdi20/pando-nsdi20.pdf">Near-optimal latency versus cost tradeoffs in geo-distributed storage</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Muhammed-Uluyol ">Muhammed&nbspUluyol</span>, 
                            <span class="pub-author pub-author-Anthony-Huang ">Anthony&nbspHuang</span>, 
                            <span class="pub-author pub-author-Ayush-Goel ">Ayush&nbspGoel</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Harsha-V. Madhyastha ">Harsha&nbspV.&nbspMadhyastha</span>
                        </div>
                        <div class="pub-conference">
                            The 17th USENIX Symposium on Networked Systems Design and Implementation
                            (<a target="_blank" title="18.36%"
                                href="https://www.usenix.org/conference/nsdi20">NSDI'20</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp18.36%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/pando:nsdi20/pando-nsdi20.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{pando:nsdi20,
    author    = {Muhammed Uluyol and Anthony Huang and Ayush Goel and Mosharaf Chowdhury and Harsha V. Madhyastha},
    booktitle = {USENIX NSDI},
    title     = {Near-Optimal Latency Versus Cost Tradeoffs in Geo-Distributed Storage},
    year      = {2020},
    pages     = {157--180},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>By replicating data across sites in multiple geo- graphic regions, web services can maximize availability and minimize latency for their users. However, when sacrificing data consistency is not an option, we show that service providers have to today incur significantly higher cost to meet desired la- tency goals than the lowest cost theoretically feasible. We show that the key to addressing this sub-optimality is to 1) allow for erasure coding, not just replication, of data across data cen- ters, and 2) mitigate the resultant increase in read and write la- tencies by rethinking how to enable consensus across the wide- area network. Our extensive evaluation mimicking web service deployments on the Azure cloud service shows that we enable near-optimal latency versus cost tradeoffs.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
            </ul>
        </section>
        <section class="year">
            <div class="year-mark-wrapper">
                <span class="year-mark" data-year="2019"></span>
            </div>
            <ul>
                <li data-pub-venue="arXiv"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Big Data Systems&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="https://arxiv.org/abs/1912.03523">BoPF: Mitigating the burstiness-fairness tradeoff in multi-resource clusters</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Tan-N. Le ">Tan&nbspN.&nbspLe</span>, 
                            <span class="pub-author pub-author-Xiao-Sun ">Xiao&nbspSun</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Zhenhua-Liu ">Zhenhua&nbspLiu</span>
                        </div>
                        <div class="pub-conference">
                            arXiv
                            (<a target="_blank" title=""
                                href="https://arxiv.org/abs/1912.03523">arXiv:1912.03523</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="https://arxiv.org/abs/1912.03523">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{bopf:arxiv19,
    author        = {Tan N. Le and Xiao Sun and Mosharaf Chowdhury and Zhenhua Liu},
    journal       = {CoRR},
    title         = {{BoPF}: Mitigating the Burstiness-Fairness Tradeoff in Multi-Resource Clusters},
    year          = {2019},
    month         = {Dec},
    volume        = {abs/1912.03523},
    archiveprefix = {arXiv},
    bibsource     = {dblp computer science bibliography, https://dblp.org},
    biburl        = {https://dblp.org/rec/journals/corr/abs-1912-03523.bib},
    eprint        = {1912.03523},
    url           = {https://arxiv.org/abs/1912.03523},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Simultaneously supporting latency- and throughout-sensitive workloads in a shared environment is an increasingly more common challenge in big data clusters. Despite many advances, existing cluster schedulers force the same performance goal - fairness in most cases - on all jobs. Latency-sensitive jobs suffer, while throughput-sensitive ones thrive. Using prioritization does the opposite: it opens up a path for latency-sensitive jobs to dominate. In this paper, we tackle the challenges in supporting both short-term performance and long-term fairness simultaneously with high resource utilization by proposing Bounded Priority Fairness (BoPF). BoPF provides short-term resource guarantees to latency-sensitive jobs and maintains long-term fairness for throughput-sensitive jobs. BoPF is the first scheduler that can provide long-term fairness, burst guarantee, and Pareto efficiency in a strategyproof manner for multi-resource scheduling. Deployments and large-scale simulations show that BoPF closely approximates the performance of Strict Priority as well as the fairness characteristics of DRF. In deployments, BoPF speeds up latency-sensitive jobs by 5.38 times compared to DRF, while still maintaining long-term fairness. In the meantime, BoPF improves the average completion times of throughput-sensitive jobs by up to 3.05 times compared to Strict Priority.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="arXiv"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Disaggregation&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="https://arxiv.org/abs/1910.09727">Mitigating the performance-efficiency tradeoff in resilient memory disaggregation</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Youngmoon-Lee ">Youngmoon&nbspLee</span>, 
                            <span class="pub-author pub-author-Hasan-Al Maruf ">Hasan&nbspAl&nbspMaruf</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Asaf-Cidon ">Asaf&nbspCidon</span>, and 
                            <span class="pub-author pub-author-Kang-G. Shin ">Kang&nbspG.&nbspShin</span>
                        </div>
                        <div class="pub-conference">
                            arXiv
                            (<a target="_blank" title=""
                                href="https://arxiv.org/abs/1910.09727">arXiv:1910.09727</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="https://arxiv.org/abs/1910.09727">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{hydra:arxiv19,
    author        = {Youngmoon Lee and Hasan Al Maruf and Mosharaf Chowdhury and Asaf Cidon and Kang G. Shin},
    journal       = {CoRR},
    title         = {Mitigating the Performance-Efficiency Tradeoff in Resilient Memory Disaggregation},
    year          = {2019},
    month         = {Oct},
    volume        = {abs/1910.09727},
    archiveprefix = {arXiv},
    bibsource     = {dblp computer science bibliography, https://dblp.org},
    biburl        = {https://dblp.org/rec/journals/corr/abs-1910-09727.bib},
    eprint        = {1910.09727},
    url           = {https://arxiv.org/abs/1910.09727},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Memory disaggregation has received attention in recent years as a promising idea to reduce the total cost of ownership (TCO) of memory in modern datacenters. However, relying on remote memory expands an applications failure domain and makes it susceptible to tail latency variations. In attempts to making disaggregated memory resilient, stateof-the-art solutions face the classic tradeoff between performance and efficiency: some double the memory overhead of disaggregation by replicating to remote memory, while many others limit performance by replicating to the local disk.</p>
<p>We present Hydra, a configurable, erasure-coded resilience mechanism for common memory disaggregation solutions. It can transparently handle uncertainties arising from remote failures, evictions, memory corruptions, and stragglers from network imbalance with a significantly better performanceefficiency tradeoff than the state-of-the-art. We design a finetuned data path to achieve single s read/write latency to remote memory, develop decentralized algorithms for clusterwide memory management, and analyze how to select parameters to mitigate independent and correlated uncertainties. Our integration of Hydra with two major memory disaggregation systems and evaluation on a 50-machine RDMA cluster demonstrates that it achieves the best of both worlds: it improves the latency and throughput of memory-intensive applications by up to 64.78 and 20.61, respectively, over the state-of-the-art disk backup-based solution. At the same time, it provides performance similar to that of in-memory replication with 1.6 lower memory overhead.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="SPAA"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/nocs:spaa19/nocs-spaa19.pdf">Near optimal coflow scheduling in networks</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Samir-Khuller ">Samir&nbspKhuller</span>, 
                            <span class="pub-author pub-author-Manish-Purohit ">Manish&nbspPurohit</span>, 
                            <span class="pub-author pub-author-Sheng-Yang ">Sheng&nbspYang</span>, and 
                            <span class="pub-author pub-author-Jie-You ">Jie&nbspYou</span>
                        </div>
                        <div class="pub-conference">
                            The 31st ACM Symposium on Parallelism in Algorithms and Architectures
                            (<a target="_blank" title="33%"
                                href="https://spaa.acm.org/2019/">SPAA'19</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp33%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/nocs:spaa19/nocs-spaa19.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{nocs:spaa19,
    author    = {Mosharaf Chowdhury and Samir Khuller and Manish Purohit and Sheng Yang and Jie You},
    booktitle = {ACM SPAA},
    title     = {Near Optimal Coflow Scheduling in Networks},
    year      = {2019},
    pages     = {123--134},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>The coflow scheduling problem has emerged as a popular abstraction in the last few years to study data communication problems within a data center. In this basic framework, each coflow has a set of communication demands and the goal is to schedule many coflows in a manner that minimizes the total weighted completion time. A coflow is said to complete when all its communication needs are met. This problem has been extremely well studied for the case of complete bipartite graphs that model a data center with full bisection bandwidth and several approximation algorithms and effective heuristics have been proposed recently. In this work, we study a slightly different model of coflow scheduling in general graphs (to capture traffic between data centers) and develop practical and efficient approximation algorithms for it. Our main result is a randomized 2 approximation algorithm for the single path and free path model, significantly improving prior work. In addition, we demonstrate via extensive experiments that the algorithm is practical, easy to implement and performs well in practice.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="arXiv"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="https://arxiv.org/abs/1906.06851">Near optimal coflow scheduling in networks</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Samir-Khuller ">Samir&nbspKhuller</span>, 
                            <span class="pub-author pub-author-Manish-Purohit ">Manish&nbspPurohit</span>, 
                            <span class="pub-author pub-author-Sheng-Yang ">Sheng&nbspYang</span>, and 
                            <span class="pub-author pub-author-Jie-You ">Jie&nbspYou</span>
                        </div>
                        <div class="pub-conference">
                            arXiv
                            (<a target="_blank" title=""
                                href="https://arxiv.org/abs/1906.06851">arXiv:1906.06851</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="https://arxiv.org/abs/1906.06851">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{nocs:arxiv19,
    author        = {Mosharaf Chowdhury and Samir Khuller and Manish Purohit and Sheng Yang and Jie You},
    journal       = {CoRR},
    title         = {Near Optimal Coflow Scheduling in Networks},
    year          = {2019},
    month         = {Jun},
    volume        = {abs/1906.06851},
    archiveprefix = {arXiv},
    bibsource     = {dblp computer science bibliography, https://dblp.org},
    biburl        = {https://dblp.org/rec/journals/corr/abs-1906-06851.bib},
    eprint        = {1906.06851},
    url           = {https://arxiv.org/abs/1906.06851},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>The coflow scheduling problem has emerged as a popular abstraction in the last few years to study data communication problems within a data center. In this basic framework, each coflow has a set of communication demands and the goal is to schedule many coflows in a manner that minimizes the total weighted completion time. A coflow is said to complete when all its communication needs are met. This problem has been extremely well studied for the case of complete bipartite graphs that model a data center with full bisection bandwidth and several approximation algorithms and effective heuristics have been proposed recently.
In this work, we study a slightly different model of coflow scheduling in general graphs (to capture traffic between data centers) and develop practical and efficient approximation algorithms for it. Our main result is a randomized 2 approximation algorithm for the single path and free path model, significantly improving prior work. In addition, we demonstrate via extensive experiments that the algorithm is practical, easy to implement and performs well in practice.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="arXiv"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Datacenter Networking&quot;,&quot;Disaggregation&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/justitia:arxiv19/justitia-arxiv19.pdf">RDMA performance isolation with Justitia</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Yiwen-Zhang ">Yiwen&nbspZhang</span>, 
                            <span class="pub-author pub-author-Yue-Tan ">Yue&nbspTan</span>, 
                            <span class="pub-author pub-author-Brent-Stephens ">Brent&nbspStephens</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            arXiv
                            (<a target="_blank" title=""
                                href="https://arxiv.org/abs/1905.04437">arXiv:1905.04437</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/justitia:arxiv19/justitia-arxiv19.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{justitia:arxiv19,
    author        = {Yiwen Zhang and Yue Tan and Brent Stephens and Mosharaf Chowdhury},
    journal       = {CoRR},
    title         = {{RDMA} Performance Isolation With {Justitia}},
    year          = {2019},
    month         = {May},
    volume        = {abs/1905.04437},
    archiveprefix = {arXiv},
    bibsource     = {dblp computer science bibliography, https://dblp.org},
    biburl        = {https://dblp.org/rec/journals/corr/abs-1905-04437.bib},
    eprint        = {1905.04437},
    url           = {https://arxiv.org/abs/1905.04437},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Despite its increasing popularity, most of RDMAs benefits such as ultra-low latency can be achieved only when running an application in isolation. Using microbenchmarks and real open-source RDMA applications, we identify a series of performance anomalies when multiple applications coexist and show that such anomalies are pervasive across InfiniBand, RoCEv2, and iWARP. They arise due to a fundamental tradeoff between performance isolation and work conservation, which the state-of-the-art RDMA congestion control protocols such as DCQCN cannot resolve.</p>
<p>We present Justitia to address these performance anomalies. Justitia is a software-only, host-based, and easy-to-deploy solution that maximizes RNIC utilization while guaranteeing performance isolation via shaping, rate limiting, and pacing at senders. Our evaluation of Justitia on multiple RDMA implementations show that Justitia effectively isolates different types of traffic and significantly improves latency (by up to 56.9) and throughput (by up to 9.7) of real-world RDMAbased applications without compromising low CPU usage or modifying the applications.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="arXiv"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="https://arxiv.org/abs/1904.08480">Terra: Scalable cross-layer GDA optimizations</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Jie-You ">Jie&nbspYou</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            arXiv
                            (<a target="_blank" title=""
                                href="https://arxiv.org/abs/1904.08480">arXiv:1904.08480</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="https://arxiv.org/abs/1904.08480">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{terra:arxiv19,
    author        = {Jie You and Mosharaf Chowdhury},
    journal       = {CoRR},
    title         = {Terra: Scalable Cross-Layer {GDA} Optimizations},
    year          = {2019},
    month         = {Apr},
    volume        = {abs/1904.08480},
    archiveprefix = {arXiv},
    bibsource     = {dblp computer science bibliography, https://dblp.org},
    biburl        = {https://dblp.org/rec/journals/corr/abs-1904-08480.bib},
    eprint        = {1904.08480},
    url           = {https://arxiv.org/abs/1904.08480},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Geo-distributed analytics (GDA) frameworks transfer large datasets over the wide-area network (WAN). Yet existing frameworks often ignore the WAN topology. This disconnect between WAN-bound applications and the WAN itself results in missed opportunities for cross-layer optimizations. In this paper, we present Terra to bridge this gap. Instead of decoupled WAN routing and GDA transfer scheduling, Terra applies scalable cross-layer optimizations to minimize WAN transfer times for GDA jobs. We present a two-pronged approach: (i) a scalable algorithm for joint routing and scheduling to make fast decisions; and (ii) a scalable, overlay-based enforcement mechanism that avoids expensive switch rule updates in the WAN. Together, they enable Terra to quickly react to WAN uncertainties such as large bandwidth fluctuations and failures in an application-aware manner as well. Integration with the FloodLight SDN controller and Apache YARN, and evaluation on 4 workloads and 3 WAN topologies show that Terra improves the average completion times of GDA jobs by 1.55x-3.43x. GDA jobs running with Terra meets 2.82x-4.29x more deadlines and can quickly react to WAN-level events in an application-aware manner.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="NSDI"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Systems + AI&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/tiresias:nsdi19/tiresias-nsdi19.pdf">Tiresias: A GPU cluster manager for distributed deep learning</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Juncheng-Gu ">Juncheng&nbspGu</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Kang-G. Shin ">Kang&nbspG.&nbspShin</span>, 
                            <span class="pub-author pub-author-Yibo-Zhu ">Yibo&nbspZhu</span>, 
                            <span class="pub-author pub-author-Myeongjae-Jeon ">Myeongjae&nbspJeon</span>, 
                            <span class="pub-author pub-author-Junjie-Qian ">Junjie&nbspQian</span>, 
                            <span class="pub-author pub-author-Hongqiang-Harry Liu ">Hongqiang&nbspHarry&nbspLiu</span>, and 
                            <span class="pub-author pub-author-Chuanxiong-Guo ">Chuanxiong&nbspGuo</span>
                        </div>
                        <div class="pub-conference">
                            The 16th USENIX Symposium on Networked Systems Design and Implementation
                            (<a target="_blank" title="14.76%"
                                href="https://www.usenix.org/conference/nsdi19">NSDI'19</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp14.76%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/tiresias:nsdi19/tiresias-nsdi19.pdf">[paper]</a>
                            <a target="_blank" href="/publications/files/tiresias:nsdi19/tiresias-nsdi19-slides.pdf">[slides]</a>
                            <a target="_blank" href="/publications/files/tiresias:nsdi19/tiresias-nsdi19-slides.ppsx">[pps]</a>
                            <a target="_blank" href="https://github.com/SymbioticLab/Tiresias">[code]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{tiresias:nsdi19,
    author    = {Juncheng Gu and Mosharaf Chowdhury and Kang G. Shin and Yibo Zhu and Myeongjae Jeon and Junjie Qian and Hongqiang Harry Liu and Chuanxiong Guo},
    booktitle = {USENIX NSDI},
    title     = {Tiresias: A {GPU} Cluster Manager for Distributed Deep Learning},
    year      = {2019},
    pages     = {485--500},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Deep learning (DL) training jobs bring some unique challenges to existing cluster managers, such as unpredictable training times, an all-or-nothing execution model, and inflexibility in GPU sharing. Our analysis of a large GPU cluster in production shows that existing big data schedulers cause long queueing delays and low overall performance.</p>
<p>We present Tiresias, a GPU cluster manager tailored for distributed DL training jobs, which efficiently schedules and places DL jobs to reduce their job completion times (JCTs). Given that a DL jobs execution time is often unpredictable, we propose two scheduling algorithms  Discretized Two-Dimensional Gittins index relies on partial information and Discretized Two-Dimensional LAS is information-agnostic  that aim to minimize the average JCT. Additionally, we describe when the consolidated placement constraint can be relaxed, and present a placement algorithm to leverage these observations without any user input. Experiments on the Michigan ConFlux cluster with 60 P100 GPUs and large-scale trace-driven simulations show that Tiresias improves the average JCT by up to 5.5 over an Apache YARN-based resource manager used in production. More importantly, Tiresiass performance is comparable to that of solutions assuming perfect knowledge.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="arXiv"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Systems + AI&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="https://arxiv.org/abs/1902.04610">Salus: Fine-grained GPU sharing primitives for deep learning applications</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Peifeng-Yu ">Peifeng&nbspYu</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            arXiv
                            (<a target="_blank" title=""
                                href="https://arxiv.org/abs/1902.04610">arXiv:1902.04610</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="https://arxiv.org/abs/1902.04610">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{salus:arxiv19,
    author        = {Peifeng Yu and Mosharaf Chowdhury},
    journal       = {CoRR},
    title         = {Salus: Fine-Grained {GPU} Sharing Primitives for Deep Learning Applications},
    year          = {2019},
    month         = {Feb},
    volume        = {abs/1902.04610},
    archiveprefix = {arXiv},
    bibsource     = {dblp computer science bibliography, https://dblp.org},
    biburl        = {https://dblp.org/rec/journals/corr/abs-1902-04610.bib},
    eprint        = {1902.04610},
    url           = {https://arxiv.org/abs/1902.04610},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>GPU computing is becoming increasingly more popular with the proliferation of deep learning (DL) applications.
However, unlike traditional resources such as CPU or the network, modern GPUs do not natively support fine-grained sharing primitives.
Consequently, implementing common policies such as time sharing and preemption are expensive.
Worse, when a DL application cannot completely use a GPUs resources, the GPU cannot be efficiently shared between multiple applications, leading to GPU underutilization.</p>
<p>We present Salus to enable two GPU sharing primitives: fast job switching and memory sharing, in order to achieve fine-grained GPU sharing among multiple DL applications.
Salus implements an efficient, consolidated execution service that exposes the GPU to different DL applications, and enforces fine-grained sharing by performing iteration scheduling and addressing associated memory management issues.
We show that these primitives can then be used to implement flexible sharing policies such as fairness, prioritization, and packing for various use cases.
Our integration of Salus with TensorFlow and evaluation on popular DL jobs show that Salus can improve the average completion time of DL training jobs by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3.19</mn><mo></mo></mrow><annotation encoding="application/x-tex">3.19\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mord">.</span><span class="mord">1</span><span class="mord">9</span><span class="mord"></span></span></span></span>,
GPU utilization for hyper-parameter tuning by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2.38</mn><mo></mo></mrow><annotation encoding="application/x-tex">2.38\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mord">.</span><span class="mord">3</span><span class="mord">8</span><span class="mord"></span></span></span></span>,
and GPU utilization of DL inference applications by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>42</mn><mo></mo></mrow><annotation encoding="application/x-tex">42\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mord">2</span><span class="mord"></span></span></span></span> over not sharing the GPU and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn><mo></mo></mrow><annotation encoding="application/x-tex">7\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">7</span><span class="mord"></span></span></span></span> over NVIDIA MPS with small overhead.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
            </ul>
        </section>
        <section class="year">
            <div class="year-mark-wrapper">
                <span class="year-mark" data-year="2018"></span>
            </div>
            <ul>
                <li data-pub-venue="MobiCom"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/cellscope:mobicom18/cellscope-mobicom18.pdf">Mitigating the latency-accuracy trade-off in mobile data analytics systems</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Anand-Padmanabha Iyer ">Anand&nbspPadmanabha&nbspIyer</span>, 
                            <span class="pub-author pub-author-Li-Erran Li ">Li&nbspErran&nbspLi</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Ion-Stoica ">Ion&nbspStoica</span>
                        </div>
                        <div class="pub-conference">
                            The 24th Annual International Conference on Mobile Computing and Networking
                            (<a target="_blank" title="22.46%"
                                href="https://sigmobile.org/mobicom/2018/">MobiCom'18</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp22.46%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/cellscope:mobicom18/cellscope-mobicom18.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{cellscope:mobicom18,
    author    = {Anand Padmanabha Iyer and Li Erran Li and Mosharaf Chowdhury and Ion Stoica},
    booktitle = {ACM MobiCom},
    title     = {Mitigating the Latency-Accuracy Trade-off in Mobile Data Analytics Systems},
    year      = {2018},
    pages     = {513--528},
    Abstract                 = {An increasing amount of mobile analytics is performed on data that is procured in a real-time fashion to make real-time decisions. Such tasks include simple reporting on streams to sophisticated model building. However, the practicality of these analyses are impeded in several domains because they are faced with a fundamental trade-off between data collection latency and analysis accuracy.

    In this paper, we first study this trade-off in the context of a specific domain, Cellular Radio Access Networks (RAN). We find that the trade-off can be resolved using two broad, general techniques: intelligent data grouping and task formulations that leverage domain characteristics. Based on this, we present CellScope, a system that applies a domain specific formulation and application of Multi-task Learning (MTL) to RAN performance analysis. It uses three techniques: feature engineering to transform raw data into effective features, a PCA inspired similarity metric to group data from geographically nearby base stations sharing performance commonalities, and a hybrid online-offline model for efficient model updates. Our evaluation shows that CellScope's accuracy improvements over direct application of ML range from 2.5X to 4.4X while reducing the model update overhead by up to 4.8X. We have also used CellScope to analyze an LTE network of over 2 million subscribers, where it reduced troubleshooting efforts by several magnitudes.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>An increasing amount of mobile analytics is performed on data that is procured in a real-time fashion to make real-time decisions. Such tasks include simple reporting on streams to sophisticated model building. However, the practicality of these analyses are impeded in several domains because they are faced with a fundamental trade-off between data collection latency and analysis accuracy. In this paper, we first study this trade-off in the context of a specific domain, Cellular Radio Access Networks (RAN). We find that the trade-off can be resolved using two broad, general techniques: intelligent data grouping and task formulations that leverage domain characteristics. Based on this, we present CellScope, a system that applies a domain specific formulation and application of Multi-task Learning (MTL) to RAN performance analysis. It uses three techniques: feature engineering to transform raw data into effective features, a PCA inspired similarity metric to group data from geographically nearby base stations sharing performance commonalities, and a hybrid online-offline model for efficient model updates. Our evaluation shows that CellScope's accuracy improvements over direct application of ML range from 2.5X to 4.4X while reducing the model update overhead by up to 4.8X. We have also used CellScope to analyze an LTE network of over 2 million subscribers, where it reduced troubleshooting efforts by several magnitudes.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="OSDI"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Big Data Systems&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/qoop:osdi18/qoop-osdi18.pdf">Dynamic query re-planning using QOOP</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Kshiteej-Mahajan ">Kshiteej&nbspMahajan</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Aditya-Akella ">Aditya&nbspAkella</span>, and 
                            <span class="pub-author pub-author-Shuchi-Chawla ">Shuchi&nbspChawla</span>
                        </div>
                        <div class="pub-conference">
                            The 13th USENIX Symposium on Operating Systems Design and Implementation
                            (<a target="_blank" title="18.29%"
                                href="https://www.usenix.org/conference/osdi18">OSDI'18</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp18.29%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/qoop:osdi18/qoop-osdi18.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{qoop:osdi18,
    author    = {Kshiteej Mahajan and Mosharaf Chowdhury and Aditya Akella and Shuchi Chawla},
    booktitle = {USENIX OSDI},
    title     = {Dynamic Query Re-Planning using {QOOP}},
    year      = {2018},
    pages     = {253--267},
    Abstract                 = {Modern data processing clusters are highly dynamic  both in terms of the number of concurrently running jobs and their resource usage. To improve job performance, recent works have focused on optimizing the cluster scheduler and the jobs' query planner with a focus on picking the right query execution plan (QEP)  represented as a directed acyclic graph  for a job in a resource-aware manner, and scheduling jobs in a QEP-aware manner. However, because existing solutions use a fixed QEP throughout the entire execution, the inability to adapt a QEP in reaction to resource changes often leads to large performance inefficiencies.

    This paper argues for dynamic query re-planning, wherein we re-evaluate and re-plan a job's QEP during its execution. We show that designing for re-planning requires fundamental changes to the interfaces between key layers of data analytics stacks today, i.e., the query planner, the execution engine, and the cluster scheduler. Instead of pushing more complexity into the scheduler or the query planner, we argue for a redistribution of responsibilities between the three components to simplify their designs. Under this redesign, we analytically show that a greedy algorithm for re-planning and execution alongside a simple max-min fair scheduler can offer provably competitive behavior even under adversarial resource changes. We prototype our algorithms atop Apache Hive and Tez. Via extensive experiments, we show that our design can offer a median performance improvement of 1.47X compared to state-of-the-art alternatives.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Modern data processing clusters are highly dynamic  both in terms of the number of concurrently running jobs and their resource usage. To improve job performance, recent works have focused on optimizing the cluster scheduler and the jobs' query planner with a focus on picking the right query execution plan (QEP)  represented as a directed acyclic graph  for a job in a resource-aware manner, and scheduling jobs in a QEP-aware manner. However, because existing solutions use a fixed QEP throughout the entire execution, the inability to adapt a QEP in reaction to resource changes often leads to large performance inefficiencies. This paper argues for dynamic query re-planning, wherein we re-evaluate and re-plan a job's QEP during its execution. We show that designing for re-planning requires fundamental changes to the interfaces between key layers of data analytics stacks today, i.e., the query planner, the execution engine, and the cluster scheduler. Instead of pushing more complexity into the scheduler or the query planner, we argue for a redistribution of responsibilities between the three components to simplify their designs. Under this redesign, we analytically show that a greedy algorithm for re-planning and execution alongside a simple max-min fair scheduler can offer provably competitive behavior even under adversarial resource changes. We prototype our algorithms atop Apache Hive and Tez. Via extensive experiments, we show that our design can offer a median performance improvement of 1.47X compared to state-of-the-art alternatives.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="APNet"
                    data-pub-cat="Workshops"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Datacenter Networking&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/pdd:apnet18/pdd-apnet18.pdf">Pas de deux: Shape the Circuits, and Shape the Apps too!</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Hong-Zhang ">Hong&nbspZhang</span>, 
                            <span class="pub-author pub-author-Kai-Chen ">Kai&nbspChen</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            The 2nd Asia-Pacific Workshop on Networking
                            (<a target="_blank" title=""
                                href="https://conferences.sigcomm.org/events/apnet2018/index.html">APNet'18</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/pdd:apnet18/pdd-apnet18.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{pdd:apnet18,
    author    = {Hong Zhang and Kai Chen and Mosharaf Chowdhury},
    booktitle = {ACM APNet},
    title     = {Pas de deux: Shape the Circuits, and Shape the Apps too!},
    year      = {2018},
    pages     = {29--35},
    Abstract                 = {Despite continued efforts toward building high bandwidth, low cost datacenter networks with reconfigurable optical fabrics, the impact of optical networks on datacenter applications has received little attention. Given the constraints of optical networks and the semantics of datacenter applications, we believe the network-application intersection to be the next innovation hotspot. In this paper, we specifically focus on data-parallel applications for two primary reasons: they are a natural fit to exploit high bandwidth optical fabrics, and they often form structured communication patterns or coflows.

    We show that configuring circuits in reaction to changing traffic patterns is not enough. Efficient scheduling of even a single coflow in optical networks should be a "Pas de deux"  a joint shaping of not only the underlying circuit, but also the applications traffic demand. Our preliminary evaluation with a production trace shows that joint shaping is on average within 1.18X of the optimal and performs 30% better than solu- tions that configure circuits in application-agnostic fashions. We further extend our analysis to inter-coflow scheduling and propose a layered solution that jointly considers circuit reconfiguration, coflow prioritization, as well as flow rate and route assignments.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Despite continued efforts toward building high bandwidth, low cost datacenter networks with reconfigurable optical fabrics, the impact of optical networks on datacenter applications has received little attention. Given the constraints of optical networks and the semantics of datacenter applications, we believe the network-application intersection to be the next innovation hotspot. In this paper, we specifically focus on data-parallel applications for two primary reasons: they are a natural fit to exploit high bandwidth optical fabrics, and they often form structured communication patterns or coflows. We show that configuring circuits in reaction to changing traffic patterns is not enough. Efficient scheduling of even a single coflow in optical networks should be a "Pas de deux"  a joint shaping of not only the underlying circuit, but also the applications traffic demand. Our preliminary evaluation with a production trace shows that joint shaping is on average within 1.18X of the optimal and performs 30% better than solu- tions that configure circuits in application-agnostic fashions. We further extend our analysis to inter-coflow scheduling and propose a layered solution that jointly considers circuit reconfiguration, coflow prioritization, as well as flow rate and route assignments.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="HotCloud"
                    data-pub-cat="Workshops"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/monarch:hotcloud18/monarch-hotcloud18.pdf">Monarch: Gaining command on geo-distributed graph analytics</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Anand-Padmanabha Iyer ">Anand&nbspPadmanabha&nbspIyer</span>, 
                            <span class="pub-author pub-author-Aurojit-Panda ">Aurojit&nbspPanda</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Aditya-Akella ">Aditya&nbspAkella</span>, 
                            <span class="pub-author pub-author-Scott-Shenker ">Scott&nbspShenker</span>, and 
                            <span class="pub-author pub-author-Ion-Stoica ">Ion&nbspStoica</span>
                        </div>
                        <div class="pub-conference">
                            The 10th USENIX Workshop on Hot Topics in Cloud Computing
                            (<a target="_blank" title=""
                                href="https://www.usenix.org/conference/hotcloud18">HotCloud'18</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/monarch:hotcloud18/monarch-hotcloud18.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{monarch:hotcloud18,
    author    = {Anand Padmanabha Iyer and Aurojit Panda and Mosharaf Chowdhury and Aditya Akella and Scott Shenker and Ion Stoica},
    booktitle = {USENIX HotCloud},
    title     = {Monarch: Gaining Command on Geo-Distributed Graph Analytics},
    year      = {2018},
    Abstract                 = {A number of existing and emerging application scenarios generate graph-structured data in a geo-distributed fashion. Although there is a lot of interest in distributed graph processing systems, none of them support geo-distributed graph processing. Geo-distributed analytics, on the other hand, has not focused on iterative workloads such as distributed graph processing.

    In this paper, we look at the problem of efficient geo-distributed graph analytics. We find that optimizing the iterative processing style of graph-parallel systems is the key to achieving this goal rather than extending existing geo-distributed techniques to graph processing. Based on this, we discuss our proposal on building Monarch, the first system to our knowledge that focuses on geo-distributed graph processing. Our preliminary evaluation of Monarch shows encouraging results.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>A number of existing and emerging application scenarios generate graph-structured data in a geo-distributed fashion. Although there is a lot of interest in distributed graph processing systems, none of them support geo-distributed graph processing. Geo-distributed analytics, on the other hand, has not focused on iterative workloads such as distributed graph processing. In this paper, we look at the problem of efficient geo-distributed graph analytics. We find that optimizing the iterative processing style of graph-parallel systems is the key to achieving this goal rather than extending existing geo-distributed techniques to graph processing. Based on this, we discuss our proposal on building Monarch, the first system to our knowledge that focuses on geo-distributed graph processing. Our preliminary evaluation of Monarch shows encouraging results.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="HotCloud"
                    data-pub-cat="Workshops"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/relay:hotcloud18/relay-hotcloud18.pdf">To relay or not to relay for inter-cloud transfers?</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Fan-Lai ">Fan&nbspLai</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Harsha-V. Madhyastha ">Harsha&nbspV.&nbspMadhyastha</span>
                        </div>
                        <div class="pub-conference">
                            The 10th USENIX Workshop on Hot Topics in Cloud Computing
                            (<a target="_blank" title=""
                                href="https://www.usenix.org/conference/hotcloud18">HotCloud'18</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/relay:hotcloud18/relay-hotcloud18.pdf">[paper]</a>
                            <a target="_blank" href="/publications/files/relay:hotcloud18/relay-hotcloud18-slides.pdf">[slides]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{relay:hotcloud18,
    author    = {Fan Lai and Mosharaf Chowdhury and Harsha V. Madhyastha},
    booktitle = {USENIX HotCloud},
    title     = {To Relay or Not to Relay for Inter-Cloud Transfers?},
    year      = {2018},
    Abstract    = {
    Efficient big data analytics over the wide-area network (WAN) is becoming increasingly more popular. Current geo-distributed analytics (GDA) systems employ WANaware optimizations to tackle WAN heterogeneities. Although extensive measurements on public clouds suggest the potential for improving inter-datacenter data transfers via detours, we show that such optimizations are unlikely to work in practice. This is because the widely accepted mantra used in a large body of literature  WAN bandwidth has high variability  can be misleading. Instead, our measurements across 40 datacenters belonging to Amazon EC2, Microsoft Azure, and Google Cloud Platform show that the available WAN bandwidth is often spatially homogeneous and temporally stable between two virtual machines (VMs) in different datacenters, even though it can be heterogeneous at the TCP flow level. Moreover, there is little scope for either bandwidth or latency optimization in a cost-effective manner via relaying. We believe that these findings will motivate the community to rethink the design rationales of GDA systems and geo-distributed services.
  }
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Efficient big data analytics over the wide-area network (WAN) is becoming increasingly more popular. Current geo-distributed analytics (GDA) systems employ WANaware optimizations to tackle WAN heterogeneities. Although extensive measurements on public clouds suggest the potential for improving inter-datacenter data transfers via detours, we show that such optimizations are unlikely to work in practice. This is because the widely accepted mantra used in a large body of literature  WAN bandwidth has high variability  can be misleading. Instead, our measurements across 40 datacenters belonging to Amazon EC2, Microsoft Azure, and Google Cloud Platform show that the available WAN bandwidth is often spatially homogeneous and temporally stable between two virtual machines (VMs) in different datacenters, even though it can be heterogeneous at the TCP flow level. Moreover, there is little scope for either bandwidth or latency optimization in a cost-effective manner via relaying. We believe that these findings will motivate the community to rethink the design rationales of GDA systems and geo-distributed services.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="MAMA"
                    data-pub-cat="Workshops"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Systems + AI&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/allox:mama18/allox-mama18.pdf">Fair allocation of heterogeneous and interchangeable resources</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Xiao-Sun ">Xiao&nbspSun</span>, 
                            <span class="pub-author pub-author-Tan-N. Le ">Tan&nbspN.&nbspLe</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Zhenhua-Liu ">Zhenhua&nbspLiu</span>
                        </div>
                        <div class="pub-conference">
                            The 20th Workshop on MAthematical performance Modeling and Analysis (MAMA)
                            (<a target="_blank" title=""
                                href="http://www.sigmetrics.org/mama/2018/">MAMA'18</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/allox:mama18/allox-mama18.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{allox:mama18,
    author    = {Xiao Sun and Tan N. Le and Mosharaf Chowdhury and Zhenhua Liu},
    booktitle = {ACM SIGMETRICS MAMA},
    title     = {Fair Allocation of Heterogeneous and Interchangeable Resources},
    year      = {2018},
    Abstract                 = {Motivated by the proliferation of heterogeneous processors such as multi-core CPUs, GPUs, TPUs, and other accelerators for machine learning, we formulate a novel multi-interchangeable resource allocation (MIRA) problem where some resources are interchangeable. The challenge is how to allocate interchangeable resources to users in a sharing system while maintaining desirable properties such as sharing incentive, Pareto efficiency, and envy-freeness. In this paper, we first show that existing algorithms, including the Dominant Resource Fairness used in production systems, fail to provide these properties for interchangeable resources. Then we characterize the tradeoff between performance and strategyproofness, and design the Budget-based (BUD) algorithm, which preserves Pareto efficiency, sharing incentive and envy-freeness while providing better performance over currently used algorithms.
}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Motivated by the proliferation of heterogeneous processors such as multi-core CPUs, GPUs, TPUs, and other accelerators for machine learning, we formulate a novel multi-interchangeable resource allocation (MIRA) problem where some resources are interchangeable. The challenge is how to allocate interchangeable resources to users in a sharing system while maintaining desirable properties such as sharing incentive, Pareto efficiency, and envy-freeness. In this paper, we first show that existing algorithms, including the Dominant Resource Fairness used in production systems, fail to provide these properties for interchangeable resources. Then we characterize the tradeoff between performance and strategyproofness, and design the Budget-based (BUD) algorithm, which preserves Pareto efficiency, sharing incentive and envy-freeness while providing better performance over currently used algorithms.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="GRADES-NDA"
                    data-pub-cat="Workshops"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Big Data Systems&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[&quot;Best Paper Award&quot;]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/aga:grades-nda18/aga-grades-nda18.pdf">Bridging the GAP: Towards approximate graph analytics</a>
                            
                        </div>
                        <div class="pub-badges">
                            <span class="Label Label--danger pub-badge">Best Paper Award</span>
                        </div>
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Anand-Padmanabha Iyer ">Anand&nbspPadmanabha&nbspIyer</span>, 
                            <span class="pub-author pub-author-Aurojit-Panda ">Aurojit&nbspPanda</span>, 
                            <span class="pub-author pub-author-Shivaram-Venkataraman ">Shivaram&nbspVenkataraman</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Aditya-Akella ">Aditya&nbspAkella</span>, 
                            <span class="pub-author pub-author-Scott-Shenker ">Scott&nbspShenker</span>, and 
                            <span class="pub-author pub-author-Ion-Stoica ">Ion&nbspStoica</span>
                        </div>
                        <div class="pub-conference">
                            The 1st Joint International Workshop on Graph Data Management Experiences & Systems (GRADES) and Network Data Analytics (NDA)
                            (<a target="_blank" title=""
                                href="https://sites.google.com/site/gradesnda2018/">GRADES-NDA'18</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/aga:grades-nda18/aga-grades-nda18.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{aga:grades-nda18,
    author    = {Anand Padmanabha Iyer and Aurojit Panda and Shivaram Venkataraman and Mosharaf Chowdhury and Aditya Akella and Scott Shenker and Ion Stoica},
    booktitle = {ACM SIGMOD GRADES-NDA},
    title     = {Bridging the {GAP}: Towards Approximate Graph analytics},
    year      = {2018},
    Abstract                 = {While there has been a tremendous interest in processing data that has an underlying graph structure, existing distributed graph processing systems take several minutes or even hours to execute popular graph algorithms. However, in several cases, providing an approximate answer is good enough. Approximate analytics is seeing considerable attention in big data due to its ability to produce timely results by trading accuracy, but they do not support graph analytics. In this paper, we bridge this gap and take a first attempt at realizing approximate graph analytics. We discuss how traditional approximate analytics techniques do not carry over to the graph usecase. Leveraging the characteristics of graph properties and algorithms, we propose a graph sparsification technique, and a machine learning based approach to choose the apt amount of sparsification required to meet a given budget. Our preliminary evaluations show encouraging results.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>While there has been a tremendous interest in processing data that has an underlying graph structure, existing distributed graph processing systems take several minutes or even hours to execute popular graph algorithms. However, in several cases, providing an approximate answer is good enough. Approximate analytics is seeing considerable attention in big data due to its ability to produce timely results by trading accuracy, but they do not support graph analytics. In this paper, we bridge this gap and take a first attempt at realizing approximate graph analytics. We discuss how traditional approximate analytics techniques do not carry over to the graph usecase. Leveraging the characteristics of graph properties and algorithms, we propose a graph sparsification technique, and a machine learning based approach to choose the apt amount of sparsification required to meet a given budget. Our preliminary evaluations show encouraging results.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="SIGMOD"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Datacenter Networking&quot;,&quot;Disaggregation&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/dslr:sigmod18/dslr-sigmod18.pdf">Distributed lock management with RDMA: Decentralization without starvation</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Dong-Young Yoon ">Dong&nbspYoung&nbspYoon</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Barzan-Mozafari ">Barzan&nbspMozafari</span>
                        </div>
                        <div class="pub-conference">
                            The 2018 ACM SIGMOD/PODS Conference
                            (<a target="_blank" title="19.52%"
                                href="http://sigmod2018.org/">SIGMOD'18</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp19.52%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/dslr:sigmod18/dslr-sigmod18.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{dslr:sigmod18,
    author    = {Dong Young Yoon and Mosharaf Chowdhury and Barzan Mozafari},
    booktitle = {ACM SIGMOD},
    title     = {Distributed Lock Management with {RDMA}: Decentralization without Starvation},
    year      = {2018},
    pages     = {1571--1586},
    Abstract                 = {Lock managers are a crucial component of modern distributed systems. However, with the increasing availability of fast RDMA-enabled networks, traditional lock managers can no longer keep up with the latency and throughput requirements of modern systems. Centralized lock managers can ensure fairness and prevent starvation using global knowledge of the system, but are themselves single points of contention and failure. Consequently, they fall short in leveraging the full potential of RDMA networks. On the other hand, decentralized (RDMA-based) lock managers either completely sacrifice global knowledge to achieve higher throughput at the risk of starvation and higher tail latencies, or they resort to costly communications in order to maintain global knowledge, which can result in significantly lower throughput.
  
    In this paper, we show that it is possible for a lock manager to be fully decentralized and yet exchange the partial knowledge necessary for preventing starvation and thereby reducing tail latencies. Our main observation is that we can design a lock manager primarily using RDMA's fetch-and-add (FA) operations, which always succeed, rather than compare-and-swap (CAS) operations, which only succeed if a given condition is satisfied. While this requires us to rethink the locking mechanism from the ground up, it enables us to sidestep the performance drawbacks of the previous CAS-based proposals that relied solely on blind retries upon lock conflicts.

    Specifically, we present DSLR (Decentralized and Starvation-free Lock management with RDMA), a decentralized lock manager that targets distributed systems running on RDMA-enabled networks. We demonstrate that, despite being fully decentralized, DSLR prevents starvation and blind retries by guaranteeing first-come-first-serve (FCFS) scheduling without maintaining explicit queues. We adapt Lamport's bakery algorithm [36] to an RDMA-enabled environment with multiple bakers, utilizing only one-sided READ and atomic FA operations. Our experiments show that, on average, DSLR delivers 1.8X (and up to 2.8X) higher throughput than all existing RDMA-based lock managers, while reducing their mean and 99.9% latencies by 2.0X and 18.3X (and up to 2.5X and 47X), respectively.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Lock managers are a crucial component of modern distributed systems. However, with the increasing availability of fast RDMA-enabled networks, traditional lock managers can no longer keep up with the latency and throughput requirements of modern systems. Centralized lock managers can ensure fairness and prevent starvation using global knowledge of the system, but are themselves single points of contention and failure. Consequently, they fall short in leveraging the full potential of RDMA networks. On the other hand, decentralized (RDMA-based) lock managers either completely sacrifice global knowledge to achieve higher throughput at the risk of starvation and higher tail latencies, or they resort to costly communications in order to maintain global knowledge, which can result in significantly lower throughput. In this paper, we show that it is possible for a lock manager to be fully decentralized and yet exchange the partial knowledge necessary for preventing starvation and thereby reducing tail latencies. Our main observation is that we can design a lock manager primarily using RDMA's fetch-and-add (FA) operations, which always succeed, rather than compare-and-swap (CAS) operations, which only succeed if a given condition is satisfied. While this requires us to rethink the locking mechanism from the ground up, it enables us to sidestep the performance drawbacks of the previous CAS-based proposals that relied solely on blind retries upon lock conflicts. Specifically, we present DSLR (Decentralized and Starvation-free Lock management with RDMA), a decentralized lock manager that targets distributed systems running on RDMA-enabled networks. We demonstrate that, despite being fully decentralized, DSLR prevents starvation and blind retries by guaranteeing first-come-first-serve (FCFS) scheduling without maintaining explicit queues. We adapt Lamport's bakery algorithm [36] to an RDMA-enabled environment with multiple bakers, utilizing only one-sided READ and atomic FA operations. Our experiments show that, on average, DSLR delivers 1.8X (and up to 2.8X) higher throughput than all existing RDMA-based lock managers, while reducing their mean and 99.9% latencies by 2.0X and 18.3X (and up to 2.5X and 47X), respectively.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
            </ul>
        </section>
        <section class="year">
            <div class="year-mark-wrapper">
                <span class="year-mark" data-year="2017"></span>
            </div>
            <ul>
                <li data-pub-venue="USENIX ;login:"
                    data-pub-cat="Journals"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Disaggregation&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/infiniswap:login17/infiniswap-login17.pdf">Decentralized memory disaggregation over low-latency networks</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Juncheng-Gu ">Juncheng&nbspGu</span>, 
                            <span class="pub-author pub-author-Youngmoon-Lee ">Youngmoon&nbspLee</span>, 
                            <span class="pub-author pub-author-Yiwen-Zhang ">Yiwen&nbspZhang</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Kang-G. Shin ">Kang&nbspG.&nbspShin</span>
                        </div>
                        <div class="pub-conference">
                            USENIX ;login: Winter 2017, VOL. 42, NO. 4
                            (<a target="_blank" title=""
                                href="https://www.usenix.org/publications/login/winter2017">USENIX ;login: Winter 2017</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/infiniswap:login17/infiniswap-login17.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@article{infiniswap:login17,
    Title                    = {Decentralized Memory Disaggregation Over Low-Latency Networks},
    Author                   = {Juncheng Gu and Youngmoon Lee and Yiwen Zhang and Mosharaf Chowdhury and Kang G. Shin},
    Journal                  = {USENIX ;login:},
    Year                     = {2017},
    Month                    = {December},
    Number                   = {4},
    Pages                    = {42--48},
    Volume                   = {42},
    Abstract                 = {Memory disaggregation can expose remote memory across a cluster to local applications. However, existing proposals call for new architectures and/or new programming models, making them infeasible. We have developed a practical memory disaggregation solution, Infiniswap, which is a remote memory paging system for clusters with lowlatency, kernel-bypass networks such as RDMA. Infiniswap opportunistically harvests and transparently exposes unused memory across the cluster to unmodified applications by dividing the swap space of each machine into many chunks and distributing them to unused memory of many remote machines. For scalability, it leverages the power of many choices to perform decentralized memory chunk placements and evictions. Applications using Infiniswap receive large performance boosts when their working sets are larger than their physical memory allocations.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Memory disaggregation can expose remote memory across a cluster to local applications. However, existing proposals call for new architectures and/or new programming models, making them infeasible. We have developed a practical memory disaggregation solution, Infiniswap, which is a remote memory paging system for clusters with lowlatency, kernel-bypass networks such as RDMA. Infiniswap opportunistically harvests and transparently exposes unused memory across the cluster to unmodified applications by dividing the swap space of each machine into many chunks and distributing them to unused memory of many remote machines. For scalability, it leverages the power of many choices to perform decentralized memory chunk placements and evictions. Applications using Infiniswap receive large performance boosts when their working sets are larger than their physical memory allocations.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="SIGCOMM"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Datacenter Networking&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/hermes:sigcomm17/hermes-sigcomm17.pdf">Resilient datacenter load balancing in the wild</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Hong-Zhang ">Hong&nbspZhang</span>, 
                            <span class="pub-author pub-author-Junxue-Zhang ">Junxue&nbspZhang</span>, 
                            <span class="pub-author pub-author-Wei-Bai ">Wei&nbspBai</span>, 
                            <span class="pub-author pub-author-Kai-Chen ">Kai&nbspChen</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            The 2017 ACM SIGCOMM Conference
                            (<a target="_blank" title="14.4%"
                                href="http://conferences.sigcomm.org/sigcomm/2017/">SIGCOMM'17</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp14.4%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/hermes:sigcomm17/hermes-sigcomm17.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{hermes:sigcomm17,
    Title                    = {Resilient Datacenter Load Balancing in the Wild},
    Author                   = {Hong Zhang and Junxue Zhang and Wei Bai and Kai Chen and Mosharaf Chowdhury},
    Booktitle                = {ACM SIGCOMM},
    Year                     = {2017},
    Month                    = {August},
    Abstract                 = {Production datacenters operate under various uncertainties such as traffic dynamics, topology asymmetry, and failures. Therefore, datacenter load balancing schemes must be resilient to these uncertainties; i.e., they should accurately sense path conditions and timely react to mitigate the fallouts. Despite significant efforts, prior solutions have important drawbacks. On the one hand, solutions such as Presto and DRB are oblivious to path conditions and blindly reroute at fixed granularity. On the other hand, solutions such as CONGA and CLOVE can sense congestion, but they can only reroute when flowlets emerge; thus, they cannot always react timely to uncertainties. To make things worse, these solutions fail to detect/handle failures such as blackholes and random packet drops, which greatly degrades their performance.

In this paper, we introduce Hermes, a datacenter load balancer that is resilient to the aforementioned uncertainties. At its heart, Hermes leverages comprehensive sensing to detect path conditions including failures unattended before, and it reacts using timely yet cautious rerouting. Hermes is a practical edge-based solution with no switch modification. We have implemented Hermes with commodity switches and evaluated it through both testbed experiments and large-scale simulations. Our results show that Hermes achieves comparable performance to CONGA and Presto in normal cases, and well handles uncertainties: under asymmetries, Hermes achieves up to 10% and 20% better flow completion time (FCT) than CONGA and CLOVE; under switch failures, it outperforms all other schemes by over 32%.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Production datacenters operate under various uncertainties such as traffic dynamics, topology asymmetry, and failures. Therefore, datacenter load balancing schemes must be resilient to these uncertainties; i.e., they should accurately sense path conditions and timely react to mitigate the fallouts. Despite significant efforts, prior solutions have important drawbacks. On the one hand, solutions such as Presto and DRB are oblivious to path conditions and blindly reroute at fixed granularity. On the other hand, solutions such as CONGA and CLOVE can sense congestion, but they can only reroute when flowlets emerge; thus, they cannot always react timely to uncertainties. To make things worse, these solutions fail to detect/handle failures such as blackholes and random packet drops, which greatly degrades their performance. In this paper, we introduce Hermes, a datacenter load balancer that is resilient to the aforementioned uncertainties. At its heart, Hermes leverages comprehensive sensing to detect path conditions including failures unattended before, and it reacts using timely yet cautious rerouting. Hermes is a practical edge-based solution with no switch modification. We have implemented Hermes with commodity switches and evaluated it through both testbed experiments and large-scale simulations. Our results show that Hermes achieves comparable performance to CONGA and Presto in normal cases, and well handles uncertainties: under asymmetries, Hermes achieves up to 10% and 20% better flow completion time (FCT) than CONGA and CLOVE; under switch failures, it outperforms all other schemes by over 32%.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="KBNets"
                    data-pub-cat="Workshops"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Datacenter Networking&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/frdma:kbnets2017/frdma-kbnets2017.pdf">Performance isolation anomalies in RDMA</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Yiwen-Zhang ">Yiwen&nbspZhang</span>, 
                            <span class="pub-author pub-author-Juncheng-Gu ">Juncheng&nbspGu</span>, 
                            <span class="pub-author pub-author-Youngmoon-Lee ">Youngmoon&nbspLee</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Kang-G. Shin ">Kang&nbspG.&nbspShin</span>
                        </div>
                        <div class="pub-conference">
                            ACM SIGCOMM 2017 Workshop on Kernel-Bypass Networks
                            (<a target="_blank" title=""
                                href="https://conferences.sigcomm.org/sigcomm/2017/workshop-kbnets.html">KBNets'17</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/frdma:kbnets2017/frdma-kbnets2017.pdf">[paper]</a>
                            <a target="_blank" href="/publications/files/frdma:kbnets2017/frdma-kbnets2017-slides.pdf">[slides]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{frdma:kbnets2017,
    Title                    = {Performance Isolation Anomalies in {RDMA}},
    Author                   = {Yiwen Zhang and Juncheng Gu and Youngmoon Lee and Mosharaf Chowdhury and Kang G. Shin},
    Booktitle                = {ACM SIGCOMMKBNets},
    Year                     = {2017},
    Month                    = {August},
    Abstract                 = {To meet the increasing throughput and latency demands of modern applications, many operators are rapidly deploying RDMA in their datacenters. At the same time, developers are re-designing their software to take advantage of RDMA's benefits for individual applications. However, when it comes to RDMA's performance, many simple questions remain open.

In this paper, we consider the performance isolation characteristics of RDMA. Specifically, we conduct three sets of experiments -- three combinations of one throughput-sensitive flow and one latency-sensitive flow -- in a controlled environment, observe large discrepancies in RDMA performance with and without the presence of a competing flow, and describe our progress in identifying plausible root-causes.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>To meet the increasing throughput and latency demands of modern applications, many operators are rapidly deploying RDMA in their datacenters. At the same time, developers are re-designing their software to take advantage of RDMA's benefits for individual applications. However, when it comes to RDMA's performance, many simple questions remain open. In this paper, we consider the performance isolation characteristics of RDMA. Specifically, we conduct three sets of experiments  three combinations of one throughput-sensitive flow and one latency-sensitive flow  in a controlled environment, observe large discrepancies in RDMA performance with and without the presence of a competing flow, and describe our progress in identifying plausible root-causes.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="HotOS"
                    data-pub-cat="Workshops"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Systems + AI&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/deepstack:hotos17/deepstack-hotos17.pdf">No! Not another deep learning framework</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Linh-Nguyen ">Linh&nbspNguyen</span>, 
                            <span class="pub-author pub-author-Peifeng-Yu ">Peifeng&nbspYu</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            The 16th Workshop on Hot Topics in Operating Systems
                            (<a target="_blank" title=""
                                href="https://www.sigops.org/s/conferences/hotos/2017">HotOS'17</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/deepstack:hotos17/deepstack-hotos17.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{deepstack:hotos17,
    Title                    = {No! Not Another Deep Learning Framework},
    Author                   = {Linh Nguyen and Peifeng Yu and Mosharaf Chowdhury},
    Booktitle                = {ACM HotOS},
    Year                     = {2017},
    Month                    = {May},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>In recent years, deep learning has pervaded many areas of computing due to the confluence of an explosive growth of large-scale computing capabilities, availability of datasets, and advances in learning techniques.
While this rapid growth has resulted in diverse deep learning frameworks, it has also led to inefficiencies for both the users and developers of these frameworks.
Specifically, adopting useful techniques across frameworks  both to perform learning tasks and to optimize performance  involves significant repetitions and reinventions.</p>
<p>In this paper, we observe that despite their diverse origins, many of these frameworks share architectural similarities.
We argue that by introducing a common representation of learning tasks and a hardware abstraction model to capture compute heterogeneity, we might be able to relieve machine learning researchers from dealing with low-level systems issues and systems researchers from being tied to any specific framework.
We expect this decoupling to accelerate progress in both domains.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="NSDI"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Disaggregation&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/infiniswap:nsdi17/infiniswap-nsdi17.pdf">Efficient memory disaggregation with Infiniswap</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Juncheng-Gu ">Juncheng&nbspGu</span>, 
                            <span class="pub-author pub-author-Youngmoon-Lee ">Youngmoon&nbspLee</span>, 
                            <span class="pub-author pub-author-Yiwen-Zhang ">Yiwen&nbspZhang</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Kang-G. Shin ">Kang&nbspG.&nbspShin</span>
                        </div>
                        <div class="pub-conference">
                            The 14th USENIX Symposium on Networked Systems Design and Implementation
                            (<a target="_blank" title="18.04%"
                                href="https://www.usenix.org/conference/nsdi17">NSDI'17</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp18.04%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/infiniswap:nsdi17/infiniswap-nsdi17.pdf">[paper]</a>
                            <a target="_blank" href="/publications/files/infiniswap:nsdi17/infiniswap-nsdi17-slides.pdf">[slides]</a>
                            <a target="_blank" href="https://github.com/SymbioticLab/Infiniswap">[code]</a>
                            <a target="_blank" href="https://infiniswap.github.io/">[website]</a>
                            <a target="_blank" href="https://blog.acolyer.org/2017/05/05/efficient-memory-disaggregation-with-infiniswap/">[media]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{infiniswap:nsdi17,
    Title                    = {Efficient Memory Disaggregation with {Infiniswap}},
    Author                   = {Juncheng Gu and Youngmoon Lee and Yiwen Zhang and Mosharaf Chowdhury and Kang G. Shin},
    Booktitle                = {USENIX NSDI},
    Year                     = {2017},
    Month                    = {March},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Memory-intensive applications suffer large performance loss when their working sets do not fully fit in memory. Yet, they cannot leverage otherwise unused remote memory when paging out to disks even in the presence of large imbalance in memory utilizations across a cluster. Existing proposals for memory disaggregation call for new architectures, new hardware designs, and/or new programming models, making them infeasible.
This paper describes the design and implementation of Infiniswap, a remote memory paging system designed specifically for an RDMA network. Infiniswap opportunistically harvests and transparently exposes unused memory to unmodified applications by dividing the swap space of each machine into many slabs and distributing them across many machines remote memory. Because one-sided RDMA operations bypass remote CPUs, Infiniswap leverages the power of many choices to perform decentralized slab placements and evictions.
We have implemented and deployed Infiniswap on an RDMA cluster without any modifications to user applications or the OS and evaluated its effectiveness using multiple workloads running on unmodified VoltDB, Memcached, PowerGraph, GraphX, and Apache Spark. Using Infiniswap, throughputs of these applications improve between 4X (0.94X) to 15.4X (7.8X) over disk (Mellanox nbdX), and median and tail latencies between 5.4X (2X) and 61X (2.3X). Infiniswap achieves these with negligible remote CPU usage, whereas nbdX becomes CPU-bound. Infiniswap increases the overall memory utilization of a cluster and works well at scale.</p>

                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
            </ul>
        </section>
        <section class="year">
            <div class="year-mark-wrapper">
                <span class="year-mark" data-year="2016"></span>
            </div>
            <ul>
                <li data-pub-venue="OSDI"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Big Data Systems&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/carbyne:osdi16/carbyne-osdi16.pdf">Altruistic scheduling in multi-resource clusters</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Robert-Grandl ">Robert&nbspGrandl</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Aditya-Akella ">Aditya&nbspAkella</span>, and 
                            <span class="pub-author pub-author-Ganesh-Ananthanarayanan ">Ganesh&nbspAnanthanarayanan</span>
                        </div>
                        <div class="pub-conference">
                            The 12th USENIX Symposium on Operating Systems Design and Implementation
                            (<a target="_blank" title="18.08%"
                                href="https://www.usenix.org/conference/osdi16">OSDI'16</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp18.08%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/carbyne:osdi16/carbyne-osdi16.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{carbyne:osdi16,
    Title                    = {Altruistic Scheduling in Multi-Resource Clusters},
    Author                   = {Robert Grandl and Mosharaf Chowdhury and Aditya Akella and Ganesh Ananthanarayanan},
    Booktitle                = {USENIX OSDI},
    Year                     = {2016},
    Month                    = {October},
    Abstract                 = {Given the well-known tradeoffs between fairness, performance, and efficiency, modern cluster schedulers often prefer instantaneous fairness as their primary objective to ensure performance isolation between users and groups. However, instantaneous, short-term convergence to fairness often does not result in noticeable long-term benefits. Instead, we propose an altruistic, long-term approach, Carbyne, where jobs yield fractions of their allocated resources without impacting their own completion times. We show that leftover resources collected via altruisms of many jobs can then be rescheduled to further secondary goals such as application-level performance and cluster efficiency without impacting performance isolation. Deployments and large-scale simulations show that Carbyne closely approximates the state-of-the-art solutions (e.g., DRF) in terms of performance isolation, while providing 1.26X better efficiency and 1.59X lower average job completion time.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Given the well-known tradeoffs between fairness, performance, and efficiency, modern cluster schedulers often prefer instantaneous fairness as their primary objective to ensure performance isolation between users and groups. However, instantaneous, short-term convergence to fairness often does not result in noticeable long-term benefits. Instead, we propose an altruistic, long-term approach, Carbyne, where jobs yield fractions of their allocated resources without impacting their own completion times. We show that leftover resources collected via altruisms of many jobs can then be rescheduled to further secondary goals such as application-level performance and cluster efficiency without impacting performance isolation. Deployments and large-scale simulations show that Carbyne closely approximates the state-of-the-art solutions (e.g., DRF) in terms of performance isolation, while providing 1.26X better efficiency and 1.59X lower average job completion time.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="OSDI"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Big Data Systems&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/eccache:osdi16/eccache-osdi16.pdf">EC-Cache: Load-balanced, low-latency cluster caching with online erasure coding</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-K.-V. Rashmi ">K.&nbspV.&nbspRashmi</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Jack-Kosaian ">Jack&nbspKosaian</span>, 
                            <span class="pub-author pub-author-Ion-Stoica ">Ion&nbspStoica</span>, and 
                            <span class="pub-author pub-author-Kannan-Ramchandran ">Kannan&nbspRamchandran</span>
                        </div>
                        <div class="pub-conference">
                            The 12th USENIX Symposium on Operating Systems Design and Implementation
                            (<a target="_blank" title="18.08%"
                                href="https://www.usenix.org/conference/osdi16">OSDI'16</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp18.08%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/eccache:osdi16/eccache-osdi16.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{eccache:osdi16,
    Title                    = {{EC-Cache}: Load-Balanced, Low-Latency Cluster Caching with Online Erasure Coding},
    Author                   = {K. V. Rashmi and Mosharaf Chowdhury and Jack Kosaian and Ion Stoica and Kannan Ramchandran},
    Booktitle                = {USENIX OSDI},
    Year                     = {2016},
    Month                    = {October},
    Abstract                 = {Data-intensive clusters and object stores are increasingly relying on in-memory object caching to meet the I/O performance demands. These systems routinely face the challenges of popularity skew, background load imbalance, and server failures, which result in severe load imbalance across storage servers and degraded I/O performance. Selective replication is a commonly used technique to tackle these challenges, where the number of cached replicas of an object is proportional to its popularity. In this paper, we explore an alternative approach using erasure coding.

EC-Cache is a load-balanced, low latency cluster cache that uses online erasure coding to overcome the limitations of selective replication. EC-Cache employs erasure coding by: (i) splitting and erasure coding individual objects during writes, and (ii) late binding, wherein obtaining any k out of (k + r) splits of an object are sufficient, during reads. As compared to selective replication, EC-Cache improves load balancing by more than 3X and reduces the median and tail read latencies by more than 2X, while using the same amount of memory. EC-Cache does so using 10% additional bandwidth and a small increase in the amount of stored metadata. The benefits offered by EC-Cache are further amplified in the presence of background network load imbalance and server failures.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Data-intensive clusters and object stores are increasingly relying on in-memory object caching to meet the I/O performance demands. These systems routinely face the challenges of popularity skew, background load imbalance, and server failures, which result in severe load imbalance across storage servers and degraded I/O performance. Selective replication is a commonly used technique to tackle these challenges, where the number of cached replicas of an object is proportional to its popularity. In this paper, we explore an alternative approach using erasure coding. EC-Cache is a load-balanced, low latency cluster cache that uses online erasure coding to overcome the limitations of selective replication. EC-Cache employs erasure coding by: (i) splitting and erasure coding individual objects during writes, and (ii) late binding, wherein obtaining any k out of (k + r) splits of an object are sufficient, during reads. As compared to selective replication, EC-Cache improves load balancing by more than 3X and reduces the median and tail read latencies by more than 2X, while using the same amount of memory. EC-Cache does so using 10% additional bandwidth and a small increase in the amount of stored metadata. The benefits offered by EC-Cache are further amplified in the presence of background network load imbalance and server failures.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="SIGCOMM"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Datacenter Networking&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/coda:sigcomm16/coda-sigcomm16.pdf">CODA: Toward automatically identifying and scheduling COflows in the DArk</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Hong-Zhang ">Hong&nbspZhang</span>, 
                            <span class="pub-author pub-author-Li-Chen ">Li&nbspChen</span>, 
                            <span class="pub-author pub-author-Bairen-Yi ">Bairen&nbspYi</span>, 
                            <span class="pub-author pub-author-Kai-Chen ">Kai&nbspChen</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Yanhui-Geng ">Yanhui&nbspGeng</span>
                        </div>
                        <div class="pub-conference">
                            The 2016 ACM SIGCOMM Conference
                            (<a target="_blank" title="17.33%"
                                href="http://conferences.sigcomm.org/sigcomm/2016/">SIGCOMM'16</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp17.33%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/coda:sigcomm16/coda-sigcomm16.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{coda:sigcomm16,
    Title                    = {{CODA}: Toward Automatically Identifying and Scheduling {CO}flows in the {DA}rk},
    Author                   = {Hong Zhang and Li Chen and Bairen Yi and Kai Chen and Mosharaf Chowdhury and Yanhui Geng},
    Booktitle                = {ACM SIGCOMM},
    Year                     = {2016},
    Month                    = {August},
    Abstract                 = {Leveraging application-level requirements using coflows has recently been shown to improve application-level communication performance in data-parallel clusters. However, existing coflow-based solutions rely on modifying applications to extract coflows, making them inapplicable to many practical scenarios.

In this paper, we present CODA, a first attempt at automatically identifying and scheduling coflows without any application modifications. We employ an incremental clustering algorithm to perform fast, application-transparent coflow identification and complement it by proposing an error-tolerant coflow scheduler to mitigate occasional identification errors. Testbed experiments and large-scale simulations with production workloads show that CODA can identify coflows with over 90% accuracy, and its scheduler is robust to inaccuracies, enabling communication stages to complete 2.4X (5.1X) faster on average (95th percentile) compared to per-flow mechanisms. Overall, CODA's performance is comparable to that of solutions requiring application modifications.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Leveraging application-level requirements using coflows has recently been shown to improve application-level communication performance in data-parallel clusters. However, existing coflow-based solutions rely on modifying applications to extract coflows, making them inapplicable to many practical scenarios. In this paper, we present CODA, a first attempt at automatically identifying and scheduling coflows without any application modifications. We employ an incremental clustering algorithm to perform fast, application-transparent coflow identification and complement it by proposing an error-tolerant coflow scheduler to mitigate occasional identification errors. Testbed experiments and large-scale simulations with production workloads show that CODA can identify coflows with over 90% accuracy, and its scheduler is robust to inaccuracies, enabling communication stages to complete 2.4X (5.1X) faster on average (95th percentile) compared to per-flow mechanisms. Overall, CODA's performance is comparable to that of solutions requiring application modifications.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="arXiv"
                    data-pub-cat="Technical Reports"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Wide-Area Computing&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="https://arxiv.org/abs/1605.04652">Fast and accurate performance analysis of LTE radio access networks</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Anand-Padmanabha Iyer ">Anand&nbspPadmanabha&nbspIyer</span>, 
                            <span class="pub-author pub-author-Ion-Stoica ">Ion&nbspStoica</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Li-Erran Li ">Li&nbspErran&nbspLi</span>
                        </div>
                        <div class="pub-conference">
                            arXiv
                            (<a target="_blank" title=""
                                href="https://arxiv.org/abs/1605.04652">arXiv:1605.04652</a>)
                            
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="https://arxiv.org/abs/1605.04652">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@techreport{cellscope:tr16,
    Title                    = {Fast and Accurate Performance Analysis of {LTE} Radio Access Networks},
    Author                   = {Anand Padmanabha Iyer and Ion Stoica and Mosharaf Chowdhury and Li Erran Li},
    Institution              = {CoRR},
    Year                     = {2016},
    Month                    = {May},
    Number                   = {abs/1605.04652},
    Abstract                 = {An increasing amount of analytics is performed on data that is procured in a real-time fashion to make real-time decisions. Such tasks include simple reporting on streams to sophisticated model building. However, the practicality of such analyses are impeded in several domains because they are faced with a fundamental trade-off between data collection latency and analysis accuracy.

In this paper, we study this trade-off in the context of a specific domain, Cellular Radio Access Networks (RAN). Our choice of this domain is influenced by its commonalities with several other domains that produce real-time data, our access to a large live dataset, and their real-time nature and dimensionality which makes it a natural fit for a popular analysis technique, machine learning (ML). We find that the latency accuracy trade-off can be resolved using two broad, general techniques: intelligent data grouping and task formulations that leverage domain characteristics. Based on this, we present CellScope, a system that addresses this challenge by applying a domain specific formulation and application of Multi-task Learning (MTL) to RAN performance analysis. It achieves this goal using three techniques: feature engineering to transform raw data into effective features, a PCA inspired similarity metric to group data from geographically nearby base stations sharing performance commonalities, and a hybrid online-offline model for efficient model updates. Our evaluation of CellScope shows that its accuracy improvements over direct application of ML range from 2.5x to 4.4x while reducing the model update overhead by up to 4.8x. We have also used CellScope to analyze a live LTE consisting of over 2 million subscribers for a period of over 10 months, where it uncovered several problems and insights, some of them previously unknown.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>An increasing amount of analytics is performed on data that is procured in a real-time fashion to make real-time decisions. Such tasks include simple reporting on streams to sophisticated model building. However, the practicality of such analyses are impeded in several domains because they are faced with a fundamental trade-off between data collection latency and analysis accuracy. In this paper, we study this trade-off in the context of a specific domain, Cellular Radio Access Networks (RAN). Our choice of this domain is influenced by its commonalities with several other domains that produce real-time data, our access to a large live dataset, and their real-time nature and dimensionality which makes it a natural fit for a popular analysis technique, machine learning (ML). We find that the latency accuracy trade-off can be resolved using two broad, general techniques: intelligent data grouping and task formulations that leverage domain characteristics. Based on this, we present CellScope, a system that addresses this challenge by applying a domain specific formulation and application of Multi-task Learning (MTL) to RAN performance analysis. It achieves this goal using three techniques: feature engineering to transform raw data into effective features, a PCA inspired similarity metric to group data from geographically nearby base stations sharing performance commonalities, and a hybrid online-offline model for efficient model updates. Our evaluation of CellScope shows that its accuracy improvements over direct application of ML range from 2.5x to 4.4x while reducing the model update overhead by up to 4.8x. We have also used CellScope to analyze a live LTE consisting of over 2 million subscribers for a period of over 10 months, where it uncovered several problems and insights, some of them previously unknown.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
                <li data-pub-venue="NSDI"
                    data-pub-cat="Conferences"
                    data-pub-extra='{&quot;topic&quot;:[&quot;Datacenter Networking&quot;],&quot;tag&quot;:[],&quot;badge&quot;:[]}'
                >
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/hug:nsdi16/hug-nsdi16.pdf">HUG: Multi-resource fairness for correlated and elastic demands</a>
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Zhenhua-Liu ">Zhenhua&nbspLiu</span>, 
                            <span class="pub-author pub-author-Ali-Ghodsi ">Ali&nbspGhodsi</span>, and 
                            <span class="pub-author pub-author-Ion-Stoica ">Ion&nbspStoica</span>
                        </div>
                        <div class="pub-conference">
                            The 13th USENIX Symposium on Networked Systems Design and Implementation
                            (<a target="_blank" title="19.74%"
                                href="https://www.usenix.org/conference/nsdi16">NSDI'16</a>)
                            <span class="pub-conference-acceptance">(Acceptance&nbspRate:&nbsp19.74%)</span>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/hug:nsdi16/hug-nsdi16.pdf">[paper]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{hug:nsdi16,
    Title                    = {{HUG}: Multi-Resource Fairness for Correlated and Elastic Demands},
    Author                   = {Mosharaf Chowdhury and Zhenhua Liu and Ali Ghodsi and Ion Stoica},
    Booktitle                = {USENIX NSDI},
    Year                     = {2016},
    Month                    = {March},
    Abstract                 = {In this paper, we study how to optimally provide isolation guarantees in multi-resource environments, such as public clouds, where a tenant's demands on different resources (links) are correlated. Unlike prior work such as Dominant Resource Fairness (DRF) that assumes static and fixed demands, we consider elastic demands. Our approach generalizes canonical max-min fairness to the multi-resource setting with correlated demands, and extends DRF to elastic demands. We consider two natural optimization objectives: isolation guarantee from a tenant's viewpoint and system utilization (work conservation) from an operator's perspective. We prove that in non-cooperative environments like public cloud networks, there is a strong tradeoff between optimal isolation guarantee and work conservation when demands are elastic. Even worse, work conservation can even decrease network utilization instead of improving it when demands are inelastic. We identify the root cause behind the tradeoff and present a provably optimal allocation algorithm, High Utilization with Guarantees (HUG), to achieve maximum attainable network utilization without sacrificing the optimal isolation guarantee, strategy-proofness, and other useful properties of DRF. In cooperative environments like private datacenter networks, HUG achieves both the optimal isolation guarantee and work conservation. Analyses, simulations, and experiments show that HUG provides better isolation guarantees, higher system utilization, and better tenant-level performance than its counterparts.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>In this paper, we study how to optimally provide isolation guarantees in multi-resource environments, such as public clouds, where a tenant's demands on different resources (links) are correlated. Unlike prior work such as Dominant Resource Fairness (DRF) that assumes static and fixed demands, we consider elastic demands. Our approach generalizes canonical max-min fairness to the multi-resource setting with correlated demands, and extends DRF to elastic demands. We consider two natural optimization objectives: isolation guarantee from a tenant's viewpoint and system utilization (work conservation) from an operator's perspective. We prove that in non-cooperative environments like public cloud networks, there is a strong tradeoff between optimal isolation guarantee and work conservation when demands are elastic. Even worse, work conservation can even decrease network utilization instead of improving it when demands are inelastic. We identify the root cause behind the tradeoff and present a provably optimal allocation algorithm, High Utilization with Guarantees (HUG), to achieve maximum attainable network utilization without sacrificing the optimal isolation guarantee, strategy-proofness, and other useful properties of DRF. In cooperative environments like private datacenter networks, HUG achieves both the optimal isolation guarantee and work conservation. Analyses, simulations, and experiments show that HUG provides better isolation guarantees, higher system utilization, and better tenant-level performance than its counterparts.
                                </blockquote>
                            </div>
                        </div>
                    </div>
                </li>
            </ul>
        </section>
    </div> <!-- pub-list -->
</div>
<!-- end-publist-be204cf8 -->

<script data-pjax src="/assets/publist/main.js"></script>

<hr />
<div class="note default"><h4 id="copyright-notice">Copyright notice<a class="headerlink" href="#copyright-notice"></a></h4>
<p>The documents listed above have been provided by the contributing authors as a means to ensure timely dissemination of scholarly and technical work on a noncommercial basis. Copyright and all rights therein are maintained by the authors or by other copyright holders, notwithstanding that they have offered their works here electronically. It is understood that all persons copying this information will adhere to the terms and constraints invoked by each authors copyright. These works may not be reposted without the explicit permission of the copyright holder.</p>
</div>

      </div>
      
      
      
    </div>

    
    


</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2016  
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SymbioticLab</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
<script src="/js/utils.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>
  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '.page-configurations',
    '.main-inner',
    '.post-toc-wrap',
    '.languages',
    '.pjax'
  ],
  analytics: false,
  cacheBust: false,
  scrollRestoration: !CONFIG.bookmark.enable,
  scrollTo: false
});
document.addEventListener('pjax:success', () => {
  pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  const hasTOC = document.querySelector('.post-toc');
  document.querySelector('.sidebar-inner').classList.toggle('sidebar-nav-active', hasTOC);
  document.querySelector(hasTOC ? '.sidebar-nav-toc' : '.sidebar-nav-overview').click();
  NexT.utils.updateSidebarPosition();
});
</script>


  





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.css" integrity="sha256-M6KFoDq9eUpmogkDgw6+3R3ZgUPSuFXnQyr8tskSfQs=" crossorigin="anonymous">



</body>
</html>
